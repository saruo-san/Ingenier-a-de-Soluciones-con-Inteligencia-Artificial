{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Zero-Shot Prompting - Prompts Sin Ejemplos Previos\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender los principios del zero-shot prompting\n",
    "- Dise√±ar prompts efectivos sin ejemplos previos\n",
    "- Aplicar t√©cnicas de instrucci√≥n clara y contexto\n",
    "- Evaluar la efectividad de diferentes enfoques zero-shot\n",
    "\n",
    "## ¬øQu√© es Zero-Shot Prompting?\n",
    "\n",
    "Zero-shot prompting es la t√©cnica donde pedimos al modelo realizar una tarea **sin proporcionar ejemplos espec√≠ficos** de c√≥mo debe hacerla. El modelo debe basarse √∫nicamente en:\n",
    "- Su entrenamiento previo\n",
    "- Las instrucciones que le damos\n",
    "- El contexto que proporcionamos\n",
    "\n",
    "### Ventajas:\n",
    "- **Simplicidad**: No requiere crear ejemplos\n",
    "- **Flexibilidad**: F√°cil de adaptar a nuevas tareas\n",
    "- **Eficiencia**: Menos tokens utilizados\n",
    "- **Generalizaci√≥n**: Funciona para tareas diversas\n",
    "\n",
    "### Limitaciones:\n",
    "- **Inconsistencia**: Resultados pueden variar m√°s\n",
    "- **Formato**: Menos control sobre la estructura de salida\n",
    "- **Tareas complejas**: Puede requerir instrucciones muy detalladas\n",
    "- **Dominio espec√≠fico**: Menos efectivo en nichos especializados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuraci√≥n inicial\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Configurar el modelo\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7  # Balance entre creatividad y consistencia\n",
    ")\n",
    "\n",
    "print(\"‚úì Modelo configurado para zero-shot prompting\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatom√≠a de un Prompt Zero-Shot Efectivo\n",
    "\n",
    "Un prompt zero-shot efectivo tiene estos componentes:\n",
    "\n",
    "1. **Contexto/Rol**: Qui√©n debe \"ser\" el modelo\n",
    "2. **Tarea**: Qu√© debe hacer espec√≠ficamente\n",
    "3. **Formato**: C√≥mo debe estructurar la respuesta\n",
    "4. **Restricciones**: Qu√© debe evitar o considerar\n",
    "5. **Input**: Los datos espec√≠ficos a procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejemplo b√°sico vs mejorado\n",
    "def comparar_prompts_basico():\n",
    "    texto = \"El nuevo iPhone tiene una bater√≠a incre√≠ble y la c√°mara es fant√°stica, pero el precio es muy alto.\"\n",
    "    \n",
    "    # Prompt b√°sico (menos efectivo)\n",
    "    prompt_basico = f\"Analiza este texto: {texto}\"\n",
    "    \n",
    "    # Prompt mejorado (m√°s efectivo)\n",
    "    prompt_mejorado = f\"\"\"Eres un analista de sentimientos experto. \n",
    "    \n",
    "Tarea: Analiza el sentimiento del siguiente texto sobre un producto.\n",
    "    \n",
    "Formato de respuesta:\n",
    "- Sentimiento general: [Positivo/Negativo/Neutral]\n",
    "- Aspectos positivos: [lista]\n",
    "- Aspectos negativos: [lista]\n",
    "- Puntuaci√≥n de confianza: [0-10]\n",
    "    \n",
    "Texto a analizar: \"{texto}\"\"\"\n",
    "    \n",
    "    print(\"=== COMPARACI√ìN DE PROMPTS ===\")\n",
    "    \n",
    "    # Probar prompt b√°sico\n",
    "    print(\"\\n1. PROMPT B√ÅSICO:\")\n",
    "    print(f\"Prompt: {prompt_basico}\")\n",
    "    try:\n",
    "        response1 = llm.invoke([HumanMessage(content=prompt_basico)])\n",
    "        print(f\"Respuesta: {response1.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    \n",
    "    # Probar prompt mejorado\n",
    "    print(\"\\n2. PROMPT MEJORADO:\")\n",
    "    print(f\"Prompt: {prompt_mejorado[:100]}...\")\n",
    "    try:\n",
    "        response2 = llm.invoke([HumanMessage(content=prompt_mejorado)])\n",
    "        print(f\"Respuesta: {response2.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n=== AN√ÅLISIS ===\")\n",
    "    print(\"‚Ä¢ Prompt b√°sico: Ambiguo, respuesta poco estructurada\")\n",
    "    print(\"‚Ä¢ Prompt mejorado: Espec√≠fico, respuesta estructurada y √∫til\")\n",
    "\n",
    "# Ejecutar comparaci√≥n\n",
    "comparar_prompts_basico()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T√©cnicas de Zero-Shot por Tipo de Tarea\n",
    "\n",
    "Diferentes tipos de tareas requieren enfoques espec√≠ficos en zero-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 1. CLASIFICACI√ìN\n",
    "def zero_shot_clasificacion():\n",
    "    print(\"=== ZERO-SHOT PARA CLASIFICACI√ìN ===\")\n",
    "    \n",
    "    emails = [\n",
    "        \"Reuni√≥n de equipo ma√±ana a las 10 AM en sala de conferencias\",\n",
    "        \"¬°Felicidades! Has ganado $1,000,000! Haz clic aqu√≠ ahora\",\n",
    "        \"Recordatorio: Tu factura de internet vence en 3 d√≠as\"\n",
    "    ]\n",
    "    \n",
    "    # Prompt optimizado para clasificaci√≥n\n",
    "    clasificacion_prompt = \"\"\"Eres un clasificador de emails empresariales.\n",
    "    \n",
    "Clasifica cada email en una de estas categor√≠as:\n",
    "- TRABAJO: Relacionado con tareas laborales\n",
    "- SPAM: Contenido no solicitado o sospechoso\n",
    "- PERSONAL: Asuntos personales o administrativos\n",
    "\n",
    "Responde solo con el nombre de la categor√≠a.\n",
    "\n",
    "Email: \"{}\"\n",
    "Categor√≠a:\"\"\"\n",
    "    \n",
    "    for i, email in enumerate(emails, 1):\n",
    "        prompt = clasificacion_prompt.format(email)\n",
    "        try:\n",
    "            response = llm.invoke([HumanMessage(content=prompt)])\n",
    "            print(f\"{i}. Email: {email[:50]}...\")\n",
    "            print(f\"   Clasificaci√≥n: {response.content.strip()}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error en email {i}: {e}\")\n",
    "\n",
    "# Ejecutar clasificaci√≥n\n",
    "zero_shot_clasificacion()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 2. GENERACI√ìN DE CONTENIDO\n",
    "def zero_shot_generacion():\n",
    "    print(\"=== ZERO-SHOT PARA GENERACI√ìN ===\")\n",
    "    \n",
    "    # Prompt estructurado para generaci√≥n\n",
    "    generacion_prompt = \"\"\"Eres un copywriter creativo especializado en redes sociales.\n",
    "    \n",
    "Tarea: Crear un post para LinkedIn sobre el tema dado.\n",
    "    \n",
    "Requisitos:\n",
    "- Tono profesional pero accesible\n",
    "- M√°ximo 150 palabras\n",
    "- Incluir 1-2 hashtags relevantes\n",
    "- Hacer una pregunta para fomentar engagement\n",
    "    \n",
    "Tema: \"Importancia del aprendizaje continuo en tecnolog√≠a\"\n",
    "    \n",
    "Post para LinkedIn:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=generacion_prompt)])\n",
    "        print(\"Post generado:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(response.content)\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # An√°lisis del resultado\n",
    "        words = len(response.content.split())\n",
    "        hashtags = response.content.count('#')\n",
    "        questions = response.content.count('?')\n",
    "        \n",
    "        print(f\"\\nAn√°lisis:\")\n",
    "        print(f\"‚Ä¢ Palabras: {words} (l√≠mite: 150)\")\n",
    "        print(f\"‚Ä¢ Hashtags: {hashtags}\")\n",
    "        print(f\"‚Ä¢ Preguntas: {questions}\")\n",
    "        print(f\"‚Ä¢ Cumple requisitos: {'‚úì' if words <= 150 and hashtags >= 1 and questions >= 1 else '‚úó'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar generaci√≥n\n",
    "zero_shot_generacion()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 3. EXTRACCI√ìN DE INFORMACI√ìN\n",
    "def zero_shot_extraccion():\n",
    "    print(\"=== ZERO-SHOT PARA EXTRACCI√ìN ===\")\n",
    "    \n",
    "    # Texto de ejemplo\n",
    "    texto_noticia = \"\"\"Apple Inc. anunci√≥ hoy que su CEO Tim Cook se reunir√° con inversores \n",
    "    el pr√≥ximo 15 de marzo de 2024 en Cupertino, California. La reuni√≥n abordar√° los \n",
    "    resultados financieros del Q1 2024, donde la compa√±√≠a report√≥ ingresos de $89.5 \n",
    "    billones. Cook tambi√©n discutir√° la nueva estrategia de IA de Apple y el lanzamiento \n",
    "    del iPhone 16 programado para septiembre. Las acciones de Apple (AAPL) subieron \n",
    "    3.2% tras el anuncio.\"\"\"\n",
    "    \n",
    "    # Prompt para extracci√≥n estructurada\n",
    "    extraccion_prompt = f\"\"\"Eres un analista financiero experto en extraer datos clave.\n",
    "    \n",
    "Extrae la siguiente informaci√≥n del texto dado:\n",
    "    \n",
    "Formato de respuesta (JSON):\n",
    "{{\n",
    "  \"empresa\": \"nombre de la empresa\",\n",
    "  \"ceo\": \"nombre del CEO\",\n",
    "  \"fecha_evento\": \"fecha del evento\",\n",
    "  \"ubicacion\": \"ubicaci√≥n del evento\",\n",
    "  \"ingresos\": \"cifra de ingresos mencionada\",\n",
    "  \"productos\": [\"lista de productos mencionados\"],\n",
    "  \"cambio_acciones\": \"porcentaje de cambio en acciones\"\n",
    "}}\n",
    "    \n",
    "Texto: \"{texto_noticia}\"\n",
    "    \n",
    "JSON:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=extraccion_prompt)])\n",
    "        print(\"Informaci√≥n extra√≠da:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Intentar parsear como JSON para validar formato\n",
    "        import json\n",
    "        try:\n",
    "            data = json.loads(response.content)\n",
    "            print(\"\\n‚úì Formato JSON v√°lido\")\n",
    "            print(f\"‚úì Campos extra√≠dos: {len(data)} elementos\")\n",
    "        except:\n",
    "            print(\"\\n‚úó Formato JSON inv√°lido - necesita refinamiento del prompt\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar extracci√≥n\n",
    "zero_shot_extraccion()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizaci√≥n de Prompts Zero-Shot\n",
    "\n",
    "T√©cnicas para mejorar la efectividad de prompts zero-shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# T√©cnica 1: Prompts con Roles Espec√≠ficos\n",
    "def roles_especificos():\n",
    "    print(\"=== OPTIMIZACI√ìN: ROLES ESPEC√çFICOS ===\")\n",
    "    \n",
    "    pregunta = \"¬øC√≥mo puedo mejorar el rendimiento de mi aplicaci√≥n web?\"\n",
    "    \n",
    "    roles = {\n",
    "        \"Gen√©rico\": \"Responde la siguiente pregunta:\",\n",
    "        \"Desarrollador Senior\": \"Eres un desarrollador senior con 10 a√±os de experiencia en optimizaci√≥n web. Responde como un experto:\",\n",
    "        \"Consultor de Performance\": \"Eres un consultor especializado en performance web que ha optimizado cientos de aplicaciones. Proporciona una respuesta detallada y t√©cnica:\",\n",
    "        \"CTO\": \"Eres un CTO de una startup tecnol√≥gica. Responde con una perspectiva estrat√©gica y t√©cnica balanceada:\"\n",
    "    }\n",
    "    \n",
    "    for rol, contexto in roles.items():\n",
    "        prompt = f\"{contexto}\\n\\n{pregunta}\"\n",
    "        \n",
    "        print(f\"\\n{rol.upper()}:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        try:\n",
    "            response = llm.invoke([HumanMessage(content=prompt)])\n",
    "            # Mostrar solo las primeras l√≠neas para comparaci√≥n\n",
    "            preview = response.content[:200] + \"...\" if len(response.content) > 200 else response.content\n",
    "            print(preview)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n=== OBSERVACIONES ===\")\n",
    "    print(\"‚Ä¢ Roles espec√≠ficos generan respuestas m√°s enfocadas\")\n",
    "    print(\"‚Ä¢ La experticia del rol influye en la profundidad t√©cnica\")\n",
    "    print(\"‚Ä¢ El contexto profesional afecta el tipo de soluciones propuestas\")\n",
    "\n",
    "# Ejecutar ejemplo de roles\n",
    "roles_especificos()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# T√©cnica 2: Instrucciones Graduales\n",
    "def instrucciones_graduales():\n",
    "    print(\"=== OPTIMIZACI√ìN: INSTRUCCIONES GRADUALES ===\")\n",
    "    \n",
    "    # Problema complejo para demostrar\n",
    "    problema = \"Necesito crear una estrategia de marketing digital para lanzar una nueva app de fitness\"\n",
    "    \n",
    "    # Prompt con instrucciones graduales\n",
    "    prompt_gradual = f\"\"\"Eres un estratega de marketing digital senior.\n",
    "    \n",
    "Problema: {problema}\n",
    "    \n",
    "Desarrolla una estrategia siguiendo este proceso paso a paso:\n",
    "    \n",
    "PASO 1: An√°lisis inicial\n",
    "- Identifica el p√∫blico objetivo\n",
    "- Define 3 puntos de valor √∫nicos de la app\n",
    "    \n",
    "PASO 2: Canales de marketing\n",
    "- Selecciona 4-5 canales digitales m√°s efectivos\n",
    "- Justifica cada selecci√≥n\n",
    "    \n",
    "PASO 3: Estrategia de contenido\n",
    "- Define tipos de contenido para cada canal\n",
    "- Sugiere frecuencia de publicaci√≥n\n",
    "    \n",
    "PASO 4: M√©tricas y KPIs\n",
    "- Define 5 m√©tricas clave para medir √©xito\n",
    "- Sugiere herramientas de medici√≥n\n",
    "    \n",
    "Desarrolla cada paso con detalle:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_gradual)])\n",
    "        print(\"ESTRATEGIA DESARROLLADA:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(response.content)\n",
    "        \n",
    "        # An√°lisis de estructura\n",
    "        pasos_detectados = response.content.count(\"PASO\")\n",
    "        secciones = [\"an√°lisis\", \"canales\", \"contenido\", \"m√©tricas\"]\n",
    "        secciones_encontradas = sum(1 for seccion in secciones if seccion.lower() in response.content.lower())\n",
    "        \n",
    "        print(\"\\n=== AN√ÅLISIS DE ESTRUCTURA ===\")\n",
    "        print(f\"‚Ä¢ Pasos identificados: {pasos_detectados}/4\")\n",
    "        print(f\"‚Ä¢ Secciones cubiertas: {secciones_encontradas}/4\")\n",
    "        print(f\"‚Ä¢ Estructura seguida: {'‚úì' if pasos_detectados >= 3 else '‚úó'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar instrucciones graduales\n",
    "instrucciones_graduales()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casos de Uso Avanzados\n",
    "\n",
    "Aplicaciones m√°s sofisticadas de zero-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Caso de uso: An√°lisis de c√≥digo\n",
    "def analisis_codigo_zero_shot():\n",
    "    print(\"=== CASO DE USO: AN√ÅLISIS DE C√ìDIGO ===\")\n",
    "    \n",
    "    codigo_ejemplo = '''def process_user_data(users):\n",
    "    result = []\n",
    "    for user in users:\n",
    "        if user[\"age\"] > 18:\n",
    "            result.append({\n",
    "                \"name\": user[\"name\"].upper(),\n",
    "                \"email\": user[\"email\"],\n",
    "                \"status\": \"adult\"\n",
    "            })\n",
    "    return result'''\n",
    "    \n",
    "    prompt_analisis = f\"\"\"Eres un senior code reviewer con experiencia en Python.\n",
    "    \n",
    "Analiza el siguiente c√≥digo y proporciona:\n",
    "    \n",
    "1. FUNCIONALIDAD:\n",
    "   - ¬øQu√© hace este c√≥digo?\n",
    "   - ¬øCu√°l es su prop√≥sito?\n",
    "    \n",
    "2. PROBLEMAS POTENCIALES:\n",
    "   - Errores de l√≥gica\n",
    "   - Vulnerabilidades de seguridad\n",
    "   - Problemas de rendimiento\n",
    "    \n",
    "3. MEJORAS SUGERIDAS:\n",
    "   - Optimizaciones de c√≥digo\n",
    "   - Mejores pr√°cticas\n",
    "   - Manejo de errores\n",
    "    \n",
    "4. PUNTUACI√ìN DE CALIDAD: [1-10]\n",
    "    \n",
    "C√≥digo a analizar:\n",
    "```python\n",
    "{codigo_ejemplo}\n",
    "```\n",
    "    \n",
    "An√°lisis:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_analisis)])\n",
    "        print(\"AN√ÅLISIS DE C√ìDIGO:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(response.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar an√°lisis de c√≥digo\n",
    "analisis_codigo_zero_shot()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Caso de uso: Generaci√≥n de tests\n",
    "def generacion_tests_zero_shot():\n",
    "    print(\"=== CASO DE USO: GENERACI√ìN DE TESTS ===\")\n",
    "    \n",
    "    funcion_a_testear = '''def calculate_discount(price, discount_percent, user_type):\n",
    "    \"\"\"Calculate final price after discount.\n",
    "    \n",
    "    Args:\n",
    "        price (float): Original price\n",
    "        discount_percent (float): Discount percentage (0-100)\n",
    "        user_type (str): 'premium' or 'regular'\n",
    "        \n",
    "    Returns:\n",
    "        float: Final price after discount\n",
    "    \"\"\"\n",
    "    if user_type == 'premium':\n",
    "        discount_percent += 5  # Extra 5% for premium users\n",
    "    \n",
    "    discount_amount = price * (discount_percent / 100)\n",
    "    return price - discount_amount'''\n",
    "    \n",
    "    prompt_tests = f\"\"\"Eres un QA engineer experto en testing de Python.\n",
    "    \n",
    "Genera tests unitarios completos para la siguiente funci√≥n usando pytest.\n",
    "    \n",
    "Incluye tests para:\n",
    "1. Casos normales (diferentes tipos de usuario y descuentos)\n",
    "2. Casos edge (descuento 0%, 100%, valores negativos)\n",
    "3. Casos de error (tipos incorrectos, valores inv√°lidos)\n",
    "4. Tests parametrizados cuando sea apropiado\n",
    "    \n",
    "Funci√≥n a testear:\n",
    "```python\n",
    "{funcion_a_testear}\n",
    "```\n",
    "    \n",
    "Genera c√≥digo de test completo y ejecutable:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_tests)])\n",
    "        print(\"TESTS GENERADOS:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(response.content)\n",
    "        \n",
    "        # An√°lisis b√°sico de los tests generados\n",
    "        test_methods = response.content.count(\"def test_\")\n",
    "        assertions = response.content.count(\"assert\")\n",
    "        parametrize = response.content.count(\"@pytest.mark.parametrize\")\n",
    "        \n",
    "        print(\"\\n=== AN√ÅLISIS DE TESTS ===\")\n",
    "        print(f\"‚Ä¢ M√©todos de test: {test_methods}\")\n",
    "        print(f\"‚Ä¢ Assertions: {assertions}\")\n",
    "        print(f\"‚Ä¢ Tests parametrizados: {parametrize}\")\n",
    "        print(f\"‚Ä¢ Cobertura estimada: {'Alta' if test_methods >= 5 else 'Media' if test_methods >= 3 else 'Baja'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar generaci√≥n de tests\n",
    "generacion_tests_zero_shot()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejores Pr√°cticas y Limitaciones\n",
    "\n",
    "### ‚úÖ Cu√°ndo Usar Zero-Shot:\n",
    "- Tareas comunes y bien definidas\n",
    "- Cuando no tienes ejemplos disponibles\n",
    "- Para prototipado r√°pido\n",
    "- Tareas que requieren creatividad\n",
    "\n",
    "### ‚ùå Cu√°ndo NO Usar Zero-Shot:\n",
    "- Formatos de salida muy espec√≠ficos\n",
    "- Tareas de dominio muy especializado\n",
    "- Cuando la consistencia es cr√≠tica\n",
    "- Tareas complejas que requieren patrones espec√≠ficos\n",
    "\n",
    "### üéØ Mejores Pr√°cticas:\n",
    "1. **S√© espec√≠fico**: Detalla exactamente qu√© quieres\n",
    "2. **Define el formato**: Especifica c√≥mo debe verse la salida\n",
    "3. **Establece restricciones**: Qu√© debe evitar o considerar\n",
    "4. **Usa roles**: Define qui√©n debe \"ser\" el modelo\n",
    "5. **Itera y refina**: Mejora bas√°ndote en resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejercicio final: Dise√±a tu propio prompt zero-shot\n",
    "def ejercicio_personalizado():\n",
    "    print(\"=== EJERCICIO PERSONAL ===\")\n",
    "    print(\"\\nDise√±a un prompt zero-shot para esta tarea:\")\n",
    "    print(\"'Crear una descripci√≥n de trabajo atractiva para un puesto de desarrollador Python junior'\")\n",
    "    print(\"\\nEstructura sugerida:\")\n",
    "    print(\"1. Rol/Contexto del modelo\")\n",
    "    print(\"2. Tarea espec√≠fica\")\n",
    "    print(\"3. Requisitos del formato\")\n",
    "    print(\"4. Restricciones importantes\")\n",
    "    print(\"\\nTu prompt aqu√≠:\")\n",
    "    \n",
    "    # Espacio para que el estudiante dise√±e su prompt\n",
    "    prompt_estudiante = \"\"\"# COLOCA TU PROMPT AQU√ç\n",
    "    \n",
    "# Ejemplo de estructura:\n",
    "# Eres un [ROL]...\n",
    "# Tarea: [TAREA ESPEC√çFICA]...\n",
    "# Formato: [ESTRUCTURA DE SALIDA]...\n",
    "# Restricciones: [LIMITACIONES]...\n",
    "\"\"\"\n",
    "    \n",
    "    print(prompt_estudiante)\n",
    "    \n",
    "    # Prompt de ejemplo bien estructurado\n",
    "    ejemplo_prompt = \"\"\"Eres un HR Business Partner senior especializado en tecnolog√≠a con 8 a√±os de experiencia reclutando desarrolladores.\n",
    "    \n",
    "Tarea: Redacta una descripci√≥n de trabajo atractiva y realista para un puesto de Desarrollador Python Junior.\n",
    "    \n",
    "Formato requerido:\n",
    "- T√≠tulo del puesto\n",
    "- Resumen ejecutivo (2-3 l√≠neas)\n",
    "- Responsabilidades principales (4-5 puntos)\n",
    "- Requisitos t√©cnicos (separar esenciales de deseables)\n",
    "- Beneficios y cultura de empresa\n",
    "- Llamada a la acci√≥n\n",
    "    \n",
    "Restricciones:\n",
    "- M√°ximo 400 palabras\n",
    "- Lenguaje inclusivo y accesible\n",
    "- Enf√≥cate en crecimiento profesional\n",
    "- Evita jerga t√©cnica excesiva\n",
    "- S√© honesto sobre el nivel junior\n",
    "    \n",
    "Descripci√≥n de trabajo:\"\"\"\n",
    "    \n",
    "    print(\"\\n=== EJEMPLO DE PROMPT BIEN ESTRUCTURADO ===\")\n",
    "    print(ejemplo_prompt)\n",
    "    \n",
    "    # Opcional: probar el prompt ejemplo\n",
    "    print(\"\\n¬øQuieres ver el resultado del prompt ejemplo? (y/n)\")\n",
    "    # En un entorno real, aqu√≠ habr√≠a input del usuario\n",
    "    \n",
    "ejercicio_personalizado()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Zero-shot prompting** es efectivo para tareas comunes sin necesidad de ejemplos\n",
    "2. **Estructura clara** del prompt mejora significativamente los resultados\n",
    "3. **Roles espec√≠ficos** generan respuestas m√°s enfocadas y expertas\n",
    "4. **Instrucciones graduales** ayudan con tareas complejas\n",
    "5. **Formato definido** asegura salidas consistentes y √∫tiles\n",
    "\n",
    "## Pr√≥ximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos **Few-Shot Prompting**, donde aprenderemos a usar ejemplos espec√≠ficos para guiar el comportamiento del modelo y lograr mayor consistencia en tareas especializadas.\n",
    "\n",
    "### Para Practicar:\n",
    "1. Dise√±a prompts zero-shot para diferentes tipos de tareas\n",
    "2. Experimenta con diferentes roles y contextos\n",
    "3. Compara resultados con y sin estructura espec√≠fica\n",
    "4. Mide la consistencia en m√∫ltiples ejecuciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}