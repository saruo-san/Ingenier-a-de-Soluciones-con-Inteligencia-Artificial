{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Chunking y Embeddings con LangChain y GitHub Models\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Entender la necesidad de dividir documentos largos en fragmentos (chunking).\n",
    "- Aprender a usar los divisores de texto de LangChain (`RecursiveCharacterTextSplitter`).\n",
    "- Comprender qu√© son los embeddings y por qu√© son fundamentales para la b√∫squeda sem√°ntica.\n",
    "- Generar embeddings para los chunks de texto utilizando los modelos de GitHub a trav√©s de la API de OpenAI.\n",
    "\n",
    "## De la B√∫squeda por Palabras Clave a la B√∫squeda Sem√°ntica\n",
    "\n",
    "En el notebook anterior, construimos un RAG b√°sico que funcionaba con palabras clave. Sus limitaciones eran claras: no entend√≠a el significado, los sin√≥nimos o el contexto. Para superar esto, necesitamos dos procesos clave:\n",
    "\n",
    "1.  **Chunking**: Si un documento es muy largo, su embedding representar√° una idea demasiado general. Al dividirlo en chunks m√°s peque√±os y cohesivos, cada chunk representa una idea m√°s espec√≠fica. Esto hace que la b√∫squeda de similitud sea mucho m√°s precisa.\n",
    "2.  **Embeddings**: Son la pieza central de la b√∫squeda sem√°ntica. Convierten el texto (nuestros chunks) en vectores num√©ricos en un espacio multidimensional. Los textos con significados similares tendr√°n vectores cercanos en este espacio, lo que nos permite encontrar informaci√≥n relevante aunque no se usen las mismas palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Cliente de OpenAI (compatible con GitHub Models) inicializado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- Configuraci√≥n del Cliente de OpenAI ---\n",
    "def initialize_client():\n",
    "    # Aseg√∫rate de tener las variables de entorno GITHUB_BASE_URL y GITHUB_TOKEN configuradas\n",
    "    client = OpenAI(\n",
    "        base_url=os.getenv(\"GITHUB_BASE_URL\", \"https://models.inference.ai.azure.com\"),\n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\")\n",
    "    )\n",
    "    return client\n",
    "\n",
    "client = initialize_client()\n",
    "print(\"‚úì Cliente de OpenAI (compatible con GitHub Models) inicializado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. El Documento a Procesar\n",
    "\n",
    "Comenzamos con un documento de texto m√°s largo que los que usamos en el notebook anterior. Este texto sobre la historia de la inteligencia artificial es ideal para demostrar la necesidad del chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üìú Documento Original"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La historia de la inteligencia artificial (IA) es una narrativa fascinante de ambici√≥n, innovaci√≥n y perseverancia. Sus ra√≠ces se remontan a la d√©cada de 1950, cuando pioneros como Alan Turing plantearon la pregunta de si las m√°quinas pod√≠an pensar. El t√©rmino 'inteligencia artificial' fue acu√±ado por John McCarthy en 1956 en la famosa Conferencia de Dartmouth, considerada el nacimiento oficial de la IA como campo de estudio. Los primeros a√±os estuvieron marcados por un gran optimismo, con la creaci√≥n de programas como el Logic Theorist y el General Problem Solver, que pod√≠an resolver problemas de l√≥gica y teoremas matem√°ticos. Sin embargo, las limitaciones computacionales y la complejidad de los problemas del mundo real llevaron al primer 'invierno de la IA' en la d√©cada de 1970, un per√≠odo de reducci√≥n de fondos y escepticismo. El resurgimiento lleg√≥ en la d√©cada de 1980 con el auge de los sistemas expertos, programas que encapsulaban el conocimiento de un experto humano en un dominio espec√≠fico, como el diagn√≥stico m√©dico (por ejemplo, MYCIN). Estos sistemas demostraron el valor comercial de la IA, pero su fragilidad y el alto costo de mantenimiento condujeron a un segundo invierno a finales de los 80 y principios de los 90. La revoluci√≥n moderna de la IA comenz√≥ a gestarse a finales de los 90 y principios de los 2000, impulsada por tres factores clave: la disponibilidad de grandes vol√∫menes de datos (Big Data), el desarrollo de hardware m√°s potente (especialmente las GPU) y los avances en algoritmos de aprendizaje autom√°tico, en particular las redes neuronales profundas (deep learning). Hitos como la victoria de Deep Blue de IBM sobre el campe√≥n de ajedrez Garry Kasparov en 1997 y, m√°s tarde, el triunfo de AlphaGo de DeepMind en el juego de Go en 2016, demostraron el poder del aprendizaje por refuerzo y el deep learning. Hoy, vivimos en la era de los modelos de lenguaje grande (LLM) como GPT y Claude, y los modelos de difusi√≥n para la generaci√≥n de im√°genes, que han llevado la IA a la corriente principal, transformando industrias y planteando nuevas preguntas sobre el futuro de la tecnolog√≠a y la humanidad.\n",
      "Longitud del texto: 2148 caracteres.\n"
     ]
    }
   ],
   "source": [
    "long_text = (\n",
    "    \"La historia de la inteligencia artificial (IA) es una narrativa fascinante de ambici√≥n, innovaci√≥n y perseverancia. \"\n",
    "    \"Sus ra√≠ces se remontan a la d√©cada de 1950, cuando pioneros como Alan Turing plantearon la pregunta de si las m√°quinas pod√≠an pensar. \"\n",
    "    \"El t√©rmino 'inteligencia artificial' fue acu√±ado por John McCarthy en 1956 en la famosa Conferencia de Dartmouth, considerada el nacimiento oficial de la IA como campo de estudio. \"\n",
    "    \"Los primeros a√±os estuvieron marcados por un gran optimismo, con la creaci√≥n de programas como el Logic Theorist y el General Problem Solver, que pod√≠an resolver problemas de l√≥gica y teoremas matem√°ticos. \"\n",
    "    \"Sin embargo, las limitaciones computacionales y la complejidad de los problemas del mundo real llevaron al primer 'invierno de la IA' en la d√©cada de 1970, un per√≠odo de reducci√≥n de fondos y escepticismo. \"\n",
    "    \"El resurgimiento lleg√≥ en la d√©cada de 1980 con el auge de los sistemas expertos, programas que encapsulaban el conocimiento de un experto humano en un dominio espec√≠fico, como el diagn√≥stico m√©dico (por ejemplo, MYCIN). \"\n",
    "    \"Estos sistemas demostraron el valor comercial de la IA, pero su fragilidad y el alto costo de mantenimiento condujeron a un segundo invierno a finales de los 80 y principios de los 90. \"\n",
    "    \"La revoluci√≥n moderna de la IA comenz√≥ a gestarse a finales de los 90 y principios de los 2000, impulsada por tres factores clave: la disponibilidad de grandes vol√∫menes de datos (Big Data), el desarrollo de hardware m√°s potente (especialmente las GPU) y los avances en algoritmos de aprendizaje autom√°tico, en particular las redes neuronales profundas (deep learning). \"\n",
    "    \"Hitos como la victoria de Deep Blue de IBM sobre el campe√≥n de ajedrez Garry Kasparov en 1997 y, m√°s tarde, el triunfo de AlphaGo de DeepMind en el juego de Go en 2016, demostraron el poder del aprendizaje por refuerzo y el deep learning. \"\n",
    "    \"Hoy, vivimos en la era de los modelos de lenguaje grande (LLM) como GPT y Claude, y los modelos de difusi√≥n para la generaci√≥n de im√°genes, que han llevado la IA a la corriente principal, transformando industrias y planteando nuevas preguntas sobre el futuro de la tecnolog√≠a y la humanidad.\"\n",
    ")\n",
    "\n",
    "display(Markdown(\"### üìú Documento Original\"))\n",
    "print(long_text)\n",
    "print(f\"Longitud del texto: {len(long_text)} caracteres.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chunking con `RecursiveCharacterTextSplitter`\n",
    "\n",
    "LangChain ofrece varias herramientas para dividir texto. `RecursiveCharacterTextSplitter` es una de las m√°s recomendadas porque intenta dividir el texto bas√°ndose en una jerarqu√≠a de separadores (como saltos de l√≠nea dobles, saltos de l√≠nea simples, espacios, etc.) para mantener los fragmentos lo m√°s coherentes posible.\n",
    "\n",
    "-   `chunk_size`: Define el tama√±o m√°ximo de cada chunk (en caracteres).\n",
    "-   `chunk_overlap`: Define cu√°ntos caracteres se superponen entre chunks consecutivos. Esto es crucial para no perder el contexto que podr√≠a existir justo en el l√≠mite entre dos chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üß© Documento Dividido en 7 Chunks"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CHUNK 1 (Longitud: 349) ---\n",
      "La historia de la inteligencia artificial (IA) es una narrativa fascinante de ambici√≥n, innovaci√≥n y perseverancia. Sus ra√≠ces se remontan a la d√©cada de 1950, cuando pioneros como Alan Turing plantearon la pregunta de si las m√°quinas pod√≠an pensar. El t√©rmino 'inteligencia artificial' fue acu√±ado por John McCarthy en 1956 en la famosa Conferencia\n",
      "\n",
      "--- CHUNK 2 (Longitud: 349) ---\n",
      "John McCarthy en 1956 en la famosa Conferencia de Dartmouth, considerada el nacimiento oficial de la IA como campo de estudio. Los primeros a√±os estuvieron marcados por un gran optimismo, con la creaci√≥n de programas como el Logic Theorist y el General Problem Solver, que pod√≠an resolver problemas de l√≥gica y teoremas matem√°ticos. Sin embargo, las\n",
      "\n",
      "--- CHUNK 3 (Longitud: 348) ---\n",
      "l√≥gica y teoremas matem√°ticos. Sin embargo, las limitaciones computacionales y la complejidad de los problemas del mundo real llevaron al primer 'invierno de la IA' en la d√©cada de 1970, un per√≠odo de reducci√≥n de fondos y escepticismo. El resurgimiento lleg√≥ en la d√©cada de 1980 con el auge de los sistemas expertos, programas que encapsulaban el\n",
      "\n",
      "--- CHUNK 4 (Longitud: 345) ---\n",
      "sistemas expertos, programas que encapsulaban el conocimiento de un experto humano en un dominio espec√≠fico, como el diagn√≥stico m√©dico (por ejemplo, MYCIN). Estos sistemas demostraron el valor comercial de la IA, pero su fragilidad y el alto costo de mantenimiento condujeron a un segundo invierno a finales de los 80 y principios de los 90. La\n",
      "\n",
      "--- CHUNK 5 (Longitud: 339) ---\n",
      "a finales de los 80 y principios de los 90. La revoluci√≥n moderna de la IA comenz√≥ a gestarse a finales de los 90 y principios de los 2000, impulsada por tres factores clave: la disponibilidad de grandes vol√∫menes de datos (Big Data), el desarrollo de hardware m√°s potente (especialmente las GPU) y los avances en algoritmos de aprendizaje\n",
      "\n",
      "--- CHUNK 6 (Longitud: 345) ---\n",
      "GPU) y los avances en algoritmos de aprendizaje autom√°tico, en particular las redes neuronales profundas (deep learning). Hitos como la victoria de Deep Blue de IBM sobre el campe√≥n de ajedrez Garry Kasparov en 1997 y, m√°s tarde, el triunfo de AlphaGo de DeepMind en el juego de Go en 2016, demostraron el poder del aprendizaje por refuerzo y el\n",
      "\n",
      "--- CHUNK 7 (Longitud: 349) ---\n",
      "el poder del aprendizaje por refuerzo y el deep learning. Hoy, vivimos en la era de los modelos de lenguaje grande (LLM) como GPT y Claude, y los modelos de difusi√≥n para la generaci√≥n de im√°genes, que han llevado la IA a la corriente principal, transformando industrias y planteando nuevas preguntas sobre el futuro de la tecnolog√≠a y la humanidad.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Inicializar el divisor de texto\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=350,  # Tama√±o del chunk en caracteres\n",
    "    chunk_overlap=50,  # Superposici√≥n para mantener contexto\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# 2. Dividir el documento en chunks\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "\n",
    "display(Markdown(f\"### üß© Documento Dividido en {len(chunks)} Chunks\"))\n",
    "\n",
    "# 3. Mostrar los chunks resultantes\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"--- CHUNK {i+1} (Longitud: {len(chunk)}) ---\")\n",
    "    print(chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generaci√≥n de Embeddings para cada Chunk\n",
    "\n",
    "Ahora que tenemos nuestros chunks, el siguiente paso es convertirlos en vectores num√©ricos. Usaremos el modelo `text-embedding-3-small`, que es eficiente y potente.\n",
    "\n",
    "El resultado ser√° una lista de vectores, donde cada vector corresponde a un chunk de nuestro documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Se generaron 7 embeddings.\n",
      "Dimensi√≥n de cada embedding: 1536\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üîç Ejemplo: Chunk y su Embedding"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Texto del Chunk 1:**La historia de la inteligencia artificial (IA) es una narrativa fascinante de ambici√≥n, innovaci√≥n y perseverancia. Sus ra√≠ces se remontan a la d√©cada de 1950, cuando pioneros como Alan Turing plantearon la pregunta de si las m√°quinas pod√≠an pensar. El t√©rmino 'inteligencia artificial' fue acu√±ado por John McCarthy en 1956 en la famosa Conferencia\n",
      "**Embedding (primeros 10 de 1536 dimensiones):**[0.027127915993332863, 0.009841188788414001, 0.00236149481497705, -0.007694374769926071, 0.016413364559412003, -0.01881389319896698, 0.017398947849869728, 0.05039156973361969, -0.010656001977622509, -0.006372132804244757]...\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(client, texts):\n",
    "    \"\"\"Funci√≥n para obtener embeddings de una lista de textos.\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=texts\n",
    "    )\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "# Generar embeddings para todos los chunks\n",
    "try:\n",
    "    chunk_embeddings = get_embeddings(client, chunks)\n",
    "    print(f\"‚úì Se generaron {len(chunk_embeddings)} embeddings.\")\n",
    "    print(f\"Dimensi√≥n de cada embedding: {len(chunk_embeddings[0])}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al generar embeddings: {e}\")\n",
    "\n",
    "# Mostrar un ejemplo de un chunk y su embedding correspondiente\n",
    "if 'chunk_embeddings' in locals() and chunk_embeddings:\n",
    "    display(Markdown(\"### üîç Ejemplo: Chunk y su Embedding\"))\n",
    "    \n",
    "    example_index = 0\n",
    "    example_chunk = chunks[example_index]\n",
    "    example_embedding = chunk_embeddings[example_index]\n",
    "    \n",
    "    print(f\"**Texto del Chunk {example_index + 1}:**{example_chunk}\")\n",
    "    print(f\"**Embedding (primeros 10 de {len(example_embedding)} dimensiones):**{example_embedding[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusiones y Pr√≥ximos Pasos\n",
    "\n",
    "¬°Felicidades! Has completado los dos pasos fundamentales para pasar de un RAG b√°sico a uno sem√°ntico:\n",
    "\n",
    "1.  **Has dividido un documento largo en chunks manejables y coherentes.**\n",
    "2.  **Has convertido cada chunk de texto en un vector num√©rico (embedding) que captura su significado.**\n",
    "\n",
    "Con esta lista de chunks y su correspondiente lista de embeddings, ahora tienes una **base de conocimiento vectorial**. \n",
    "\n",
    "**En el pr√≥ximo notebook (`3-vector-rag.ipynb`), aprender√°s a:**\n",
    "-   Tomar una consulta del usuario y generar tambi√©n su embedding.\n",
    "-   Usar la **similitud coseno** para comparar el vector de la consulta con todos los vectores de los chunks.\n",
    "-   Seleccionar los chunks m√°s similares (los que tienen la puntuaci√≥n de similitud m√°s alta) para usarlos como contexto en la generaci√≥n de la respuesta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
