{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9019b973",
   "metadata": {},
   "source": [
    "## Primera Llamada al Modelo\n",
    "\n",
    "En este ejercicio, aprenderemos a realizar nuestra primera llamada a un modelo de lenguaje usando GitHub Models API.\n",
    "\n",
    "# 1. GitHub Models API - Conexi칩n Directa con OpenAI Client\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Configurar una conexi칩n directa con GitHub Models usando el cliente OpenAI\n",
    "- Comprender los par치metros b치sicos de configuraci칩n de API\n",
    "- Implementar llamadas b치sicas a modelos de lenguaje\n",
    "- Aplicar mejores pr치cticas de seguridad con API keys\n",
    "\n",
    "## Introducci칩n\n",
    "GitHub Models proporciona acceso a varios modelos de lenguaje mediante una API compatible con OpenAI. En este notebook aprenderemos a:\n",
    "1. Configurar el entorno y las credenciales\n",
    "2. Establecer una conexi칩n con la API\n",
    "3. Realizar llamadas b치sicas al modelo\n",
    "4. Explorar diferentes par치metros de configuraci칩n\n",
    "\n",
    "## Configuraci칩n de Variables de Entorno\n",
    "\n",
    "Antes de ejecutar el c칩digo, aseg칰rate de tener configuradas las siguientes variables de entorno:\n",
    "\n",
    "```bash\n",
    "export GITHUB_BASE_URL=\"https://models.inference.ai.azure.com\"\n",
    "export GITHUB_TOKEN=\"tu_token_de_github_aqui\"\n",
    "```\n",
    "\n",
    "**Mejores Pr치cticas de Seguridad:**\n",
    "- Nunca hardcodees API keys en el c칩digo\n",
    "- Usa variables de entorno o archivos .env\n",
    "- No compartas credenciales en repositorios p칰blicos\n",
    "- Rota las API keys regularmente\n",
    "\n",
    "## Instalaci칩n de Dependencias\n",
    "```bash\n",
    "pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab37f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI library version: 1.78.1\n",
      "Python version: 3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]\n",
      "Base URL configurada: https://models.inference.ai.azure.com\n",
      "API Key configurada: 九늎n",
      "API Key preview: ghp_OzdBEe...B8LA\n"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Verificar que tenemos las bibliotecas correctas\n",
    "print(\"OpenAI library version:\", __import__('openai').__version__)\n",
    "print(\"Python version:\", __import__('sys').version)\n",
    "\n",
    "# Configuraci칩n del cliente OpenAI para GitHub Models\n",
    "try:\n",
    "    # Configurar el cliente con variables de entorno\n",
    "    client = OpenAI(\n",
    "        base_url=os.environ.get(\"GITHUB_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"GITHUB_TOKEN\")\n",
    "    )\n",
    "    \n",
    "    # Verificar configuraci칩n (sin mostrar la API key completa por seguridad)\n",
    "    print(\"Base URL configurada:\", client.base_url)\n",
    "    print(\"API Key configurada:\", \"九늎" if client.api_key else \"九듚")\n",
    "    \n",
    "    if client.api_key:\n",
    "        print(\"API Key preview:\", client.api_key[:10] + \"...\" + client.api_key[-4:])\n",
    "    else:\n",
    "        print(\"丘멆잺  API Key no encontrada. Aseg칰rate de configurar GITHUB_TOKEN\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error en configuraci칩n: {e}\")\n",
    "    print(\"Verifica que las variables de entorno est칠n configuradas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49b487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Respuesta del Modelo ===\n",
      "춰Hola! Estoy aqu칤 y lista para ayudarte, 쯘n qu칠 puedo asistirte? 游땕\n",
      "\n",
      "=== Informaci칩n T칠cnica ===\n",
      "Modelo usado: gpt-4o-2024-11-20\n",
      "Tokens usados: 38\n",
      "Tokens de entrada: 19\n",
      "Tokens de salida: 19\n"
     ]
    }
   ],
   "source": [
    "# Primera llamada b치sica al modelo\n",
    "def llamada_basica():\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"Hola, 쯖칩mo est치s? Responde en una oraci칩n.\"}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        \n",
    "        print(\"=== Respuesta del Modelo ===\")\n",
    "        print(response.choices[0].message.content)\n",
    "        print(\"\\n=== Informaci칩n T칠cnica ===\")\n",
    "        print(f\"Modelo usado: {response.model}\")\n",
    "        print(f\"Tokens usados: {response.usage.total_tokens}\")\n",
    "        print(f\"Tokens de entrada: {response.usage.prompt_tokens}\")\n",
    "        print(f\"Tokens de salida: {response.usage.completion_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la llamada: {e}\")\n",
    "        print(\"Verifica tu configuraci칩n y conexi칩n a internet\")\n",
    "\n",
    "# Ejecutar la funci칩n\n",
    "llamada_basica()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cccf4a",
   "metadata": {},
   "source": [
    "## Usando Roles del Sistema\n",
    "\n",
    "El rol \"system\" permite establecer el comportamiento y contexto del asistente antes de la conversaci칩n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "j1b57r1oeo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Respuesta con Mensaje de Sistema ===\n",
      "춰Claro! Una API es como un **puente de comunicaci칩n** entre dos sistemas o aplicaciones que necesitan \"hablar\" entre s칤 para compartir datos o realizar acciones.\n",
      "\n",
      "Para explicarlo de una manera m치s sencilla: imagina que est치s en un restaurante. T칰 (el cliente) te sientas en la mesa y quieres pedir comida. La cocina (el sistema que prepara la comida) no interact칰a directamente contigo. En su lugar, tienes un mesero (la API), que se encarga de llevar tu pedido a la cocina y luego traerte la comida.\n",
      "\n",
      "En el mundo de la tecnolog칤a, una **API (Interfaz de Programaci칩n de Aplicaciones)** es como ese mesero. Permite que diferentes programas o aplicaciones trabajen juntos, aunque est칠n construidos de manera diferente. Lo hace proporcionando un conjunto de reglas y herramientas para que puedan comunicarse.\n",
      "\n",
      "---\n",
      "\n",
      "### Ejemplo pr치ctico\n",
      "Pensemos en una **aplicaci칩n de clima** en tu tel칠fono. Esa app no tiene\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con mensaje de sistema\n",
    "def usar_mensaje_sistema():\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"Eres un experto en tecnolog칤a que explica conceptos complejos de manera simple y amigable. Siempre incluyes ejemplos pr치cticos.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": \"쯈u칠 es una API?\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        \n",
    "        print(\"=== Respuesta con Mensaje de Sistema ===\")\n",
    "        print(response.choices[0].message.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar funci칩n\n",
    "usar_mensaje_sistema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a290e",
   "metadata": {},
   "source": [
    "## Explorando Par치metros de Configuraci칩n\n",
    "\n",
    "Los par치metros m치s importantes al hacer llamadas a LLMs son:\n",
    "\n",
    "- **temperature**: Controla la creatividad (0.0 = determin칤stico, 1.0 = muy creativo)\n",
    "- **max_tokens**: L칤mite de tokens en la respuesta\n",
    "- **model**: El modelo espec칤fico a usar (gpt-4o, gpt-3.5-turbo, etc.)\n",
    "- **messages**: Array de mensajes con roles (system, user, assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "j48bg48xqs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TEMPERATURE: 0.1\n",
      "==================================================\n",
      "En un peque침o taller lleno de herramientas y chispas, un robot llamado C1-B0, dise침ado para tareas dom칠sticas b치sicas, descubri칩 un viejo libro de recetas olvidado en un rinc칩n polvoriento. Intrigado por las im치genes coloridas de pasteles y guisos, decidi칩 intentarlo.\n",
      "\n",
      "Al principio, sus movimientos eran torpes. Derram칩 harina por todo el suelo y confundi칩 el az칰car con la sal. Pero C1-B0 ten칤a algo especial: un m칩dulo\n",
      "\n",
      "Tokens usados: 121\n",
      "\n",
      "==================================================\n",
      "TEMPERATURE: 0.5\n",
      "==================================================\n",
      "En un peque침o taller lleno de herramientas y chispas, un robot llamado C1-B0 despert칩 a la vida. Su creador, un chef jubilado llamado Don Emilio, lo hab칤a dise침ado para ayudar en la cocina, pero hab칤a olvidado un detalle crucial: C1-B0 no sab칤a nada de cocinar.\n",
      "\n",
      "La primera vez que intent칩 hacer una sopa, el robot confundi칩 sal con az칰car. El resultado fue tan desastroso que incluso el gato de Don Emilio se neg칩 a probar\n",
      "\n",
      "Tokens usados: 121\n",
      "\n",
      "==================================================\n",
      "TEMPERATURE: 0.9\n",
      "==================================================\n",
      "En un peque침o taller lleno de herramientas y cables, viv칤a un robot llamado P-42. Su creador, el se침or M칠ndez, le hab칤a construido para tareas simples del hogar. Pero un d칤a, mientras ordenaba una estanter칤a, P-42 encontr칩 un viejo libro de cocina con p치ginas amarillentas y dibujos de platillos que parec칤an obras de arte.\n",
      "\n",
      "Curioso, P-42 escane칩 las recetas. Decidi칩 probar. La primera creaci칩n fue, por decir\n",
      "\n",
      "Tokens usados: 121\n"
     ]
    }
   ],
   "source": [
    "# Comparando diferentes valores de temperature\n",
    "def comparar_temperature():\n",
    "    prompt = \"Escribe una historia muy corta sobre un robot que aprende a cocinar.\"\n",
    "    \n",
    "    temperatures = [0.1, 0.5, 0.9]\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"TEMPERATURE: {temp}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temp,\n",
    "                max_tokens=100\n",
    "            )\n",
    "            \n",
    "            print(response.choices[0].message.content)\n",
    "            print(f\"\\nTokens usados: {response.usage.total_tokens}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar comparaci칩n\n",
    "comparar_temperature()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6fc272",
   "metadata": {},
   "source": [
    "## Ejercicios Pr치cticos\n",
    "\n",
    "### Ejercicio 1: Experimentar con Diferentes Modelos\n",
    "Modifica el c칩digo para probar diferentes modelos disponibles (si tienes acceso):\n",
    "- gpt-4o\n",
    "- gpt-4o-mini\n",
    "- DeepSeek-R1-0528\n",
    "\n",
    "Revisa todos los modelos diponibles en la [documentaci칩n de Github Marketplace](https://github.com/marketplace?type=models)\n",
    "\n",
    "### Ejercicio 2: Crear un Asistente Especializado\n",
    "Dise침a un mensaje de sistema para crear un asistente especializado en un tema espec칤fico (ejemplo: finanzas, salud, educaci칩n).\n",
    "\n",
    "### Ejercicio 3: Optimizaci칩n de Tokens\n",
    "Experimenta con diferentes valores de max_tokens para encontrar el equilibrio entre respuesta completa y eficiencia de costos.\n",
    "\n",
    "## Conceptos Clave\n",
    "\n",
    "1. **Configuraci칩n segura** de APIs usando variables de entorno\n",
    "2. **Par치metros b치sicos** para controlar el comportamiento del modelo\n",
    "3. **Manejo de errores** en llamadas a APIs\n",
    "4. **Roles de mensajes** (system, user, assistant)\n",
    "5. **Monitoreo de uso** de tokens y costos\n",
    "\n",
    "## Pr칩ximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos c칩mo LangChain simplifica y abstrae estas operaciones, proporcionando herramientas m치s poderosas para el desarrollo de aplicaciones con LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
