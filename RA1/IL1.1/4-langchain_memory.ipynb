{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bmsvkxtyalo",
   "metadata": {},
   "source": [
    "# 4. LangChain Memory - Gesti√≥n de Contexto Conversacional\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender la importancia de la memoria en conversaciones con LLMs\n",
    "- Implementar diferentes tipos de memoria con LangChain\n",
    "- Gestionar el contexto de conversaciones largas\n",
    "- Optimizar el uso de tokens con estrategias de memoria\n",
    "\n",
    "## ¬øPor qu√© es Importante la Memoria?\n",
    "\n",
    "Los LLMs son **stateless** por naturaleza: no recuerdan conversaciones anteriores. La memoria permite:\n",
    "- **Contexto conversacional**: Referirse a mensajes anteriores\n",
    "- **Personalizaci√≥n**: Recordar preferencias del usuario\n",
    "- **Continuidad**: Mantener hilos de conversaci√≥n coherentes\n",
    "- **Experiencia natural**: Conversaciones que se sienten humanas\n",
    "\n",
    "## Tipos de Memoria en LangChain\n",
    "\n",
    "1. **ConversationBufferMemory**: Mantiene todo el historial\n",
    "2. **ConversationSummaryMemory**: Resume conversaciones largas\n",
    "3. **ConversationBufferWindowMemory**: Mantiene solo los N mensajes m√°s recientes\n",
    "4. **ConversationSummaryBufferMemory**: Combina resumen + buffer reciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias para memoria\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    ConversationBufferWindowMemory\n",
    ")\n",
    "from langchain.chains import ConversationChain\n",
    "import os\n",
    "\n",
    "print(\"‚úì Bibliotecas de memoria importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n del modelo para memoria\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(\"‚úì Modelo configurado para experimentos de memoria\")\n",
    "    print(f\"Modelo: {llm.model_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error en configuraci√≥n: {e}\")\n",
    "    print(\"Verifica las variables de entorno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc98272",
   "metadata": {},
   "source": [
    "## 1. ConversationBufferMemory - Memoria Completa\n",
    "\n",
    "Esta memoria mantiene **todo** el historial de la conversaci√≥n. Es la m√°s simple pero puede consumir muchos tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo b√°sico con ConversationBufferMemory\n",
    "def ejemplo_buffer_memory():\n",
    "    print(\"=== CONVERSATIONBUFFERMEMORY ===\")\n",
    "    print(\"Mantiene todo el historial de conversaci√≥n\\\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Crear memoria buffer\n",
    "        memory = ConversationBufferMemory()\n",
    "        \n",
    "        # Crear cadena de conversaci√≥n\n",
    "        conversation = ConversationChain(\n",
    "            llm=llm,\n",
    "            memory=memory,\n",
    "            verbose=True  # Muestra el prompt interno\n",
    "        )\n",
    "        \n",
    "        # Primera interacci√≥n\n",
    "        print(\"1. Primera pregunta:\")\n",
    "        response1 = conversation.predict(input=\"Mi nombre es Ana y soy programadora Python\")\n",
    "        print(f\"Respuesta: {response1}\\\\n\")\n",
    "        \n",
    "        # Segunda interacci√≥n (debe recordar el nombre)\n",
    "        print(\"2. Segunda pregunta:\")\n",
    "        response2 = conversation.predict(input=\"¬øCu√°l es mi nombre y profesi√≥n?\")\n",
    "        print(f\"Respuesta: {response2}\\\\n\")\n",
    "        \n",
    "        # Tercera interacci√≥n (debe recordar todo el contexto)\n",
    "        print(\"3. Tercera pregunta:\")\n",
    "        response3 = conversation.predict(input=\"¬øQu√© lenguaje de programaci√≥n mencion√©?\")\n",
    "        print(f\"Respuesta: {response3}\\\\n\")\n",
    "        \n",
    "        # Examinar el contenido de la memoria\n",
    "        print(\"=== CONTENIDO DE LA MEMORIA ===\")\n",
    "        print(memory.buffer)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar ejemplo\n",
    "ejemplo_buffer_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1acba3",
   "metadata": {},
   "source": [
    "## 2. ConversationBufferWindowMemory - Ventana Deslizante\n",
    "\n",
    "Esta memoria mantiene solo los **N mensajes m√°s recientes**, √∫til para controlar el uso de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46248c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo con ConversationSummaryMemory\n",
    "def ejemplo_summary_memory():\n",
    "    print(\"=== CONVERSATIONSUMMARYMEMORY ===\")\n",
    "    print(\"Resume conversaciones largas para ahorrar tokens\\\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Crear memoria con resumen\n",
    "        memory = ConversationSummaryMemory(llm=llm)\n",
    "        \n",
    "        conversation = ConversationChain(\n",
    "            llm=llm,\n",
    "            memory=memory,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Simular una conversaci√≥n larga con muchos detalles\n",
    "        long_inputs = [\n",
    "            \"Hola, me llamo Mar√≠a Gonz√°lez, tengo 35 a√±os y soy ingeniera de software especializada en desarrollo web con React y Node.js. Trabajo en una startup de fintech en Madrid desde hace 3 a√±os.\",\n",
    "            \"Mi proyecto actual involucra crear una plataforma de pagos digitales que debe manejar transacciones en tiempo real con alta seguridad. Usamos microservicios con Docker y Kubernetes.\",\n",
    "            \"El mayor desaf√≠o t√©cnico que enfrentamos es la latencia en las transacciones internacionales. Estamos considerando implementar edge computing y optimizar nuestras APIs.\",\n",
    "            \"Tambi√©n estoy trabajando en mejorar la experiencia de usuario de nuestra aplicaci√≥n m√≥vil. Los usuarios se quejan de que el proceso de verificaci√≥n de identidad es muy lento.\",\n",
    "            \"¬øPuedes resumir qui√©n soy y cu√°les son mis principales desaf√≠os profesionales?\"\n",
    "        ]\n",
    "        \n",
    "        for i, user_input in enumerate(long_inputs, 1):\n",
    "            print(f\"{i}. Input: {user_input[:100]}...\")\n",
    "            response = conversation.predict(input=user_input)\n",
    "            print(f\"   Respuesta: {response}\\\\n\")\n",
    "            \n",
    "            # Mostrar el resumen actual\n",
    "            print(\"   Resumen actual en memoria:\")\n",
    "            print(f\"   {memory.buffer}\\\\n\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar ejemplo\n",
    "ejemplo_summary_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2195b2",
   "metadata": {},
   "source": [
    "## 3. ConversationSummaryMemory - Resumen Inteligente\n",
    "\n",
    "Esta memoria **resume** conversaciones largas en lugar de mantener todo el texto completo, ahorrando tokens significativamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51070f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo con ConversationBufferWindowMemory\n",
    "def ejemplo_window_memory():\n",
    "    print(\"=== CONVERSATIONBUFFERWINDOWMEMORY ===\")\n",
    "    print(\"Mantiene solo los 2 intercambios m√°s recientes\\\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Crear memoria con ventana de 2 intercambios\n",
    "        memory = ConversationBufferWindowMemory(k=2)\n",
    "        \n",
    "        conversation = ConversationChain(\n",
    "            llm=llm,\n",
    "            memory=memory,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # M√∫ltiples interacciones para ver el efecto de la ventana\n",
    "        inputs = [\n",
    "            \"Mi nombre es Carlos y tengo 30 a√±os\",\n",
    "            \"Trabajo como dise√±ador gr√°fico\",\n",
    "            \"Me gusta el caf√© y la m√∫sica jazz\",\n",
    "            \"¬øPuedes recordar mi edad?\",  # Deber√≠a olvidar esto\n",
    "            \"¬øCu√°l es mi profesi√≥n?\"  # Deber√≠a recordar esto\n",
    "        ]\n",
    "        \n",
    "        for i, user_input in enumerate(inputs, 1):\n",
    "            print(f\"{i}. Pregunta: {user_input}\")\n",
    "            response = conversation.predict(input=user_input)\n",
    "            print(f\"   Respuesta: {response}\\\\n\")\n",
    "            \n",
    "            # Mostrar contenido actual de la memoria\n",
    "            print(f\"   Memoria actual (k=2):\")\n",
    "            print(f\"   {memory.buffer}\\\\n\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar ejemplo\n",
    "ejemplo_window_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697af2f4",
   "metadata": {},
   "source": [
    "## Comparaci√≥n de Tipos de Memoria\n",
    "\n",
    "Veamos las diferencias entre los tipos de memoria en una misma conversaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n entre tipos de memoria\n",
    "def comparar_memorias():\n",
    "    print(\"=== COMPARACI√ìN DE TIPOS DE MEMORIA ===\\\\n\")\n",
    "    \n",
    "    # Configurar diferentes tipos de memoria\n",
    "    buffer_memory = ConversationBufferMemory()\n",
    "    window_memory = ConversationBufferWindowMemory(k=2)\n",
    "    summary_memory = ConversationSummaryMemory(llm=llm)\n",
    "    \n",
    "    # Crear conversaciones con cada tipo\n",
    "    conversations = {\n",
    "        \"Buffer (Todo)\": ConversationChain(llm=llm, memory=buffer_memory, verbose=False),\n",
    "        \"Window (k=2)\": ConversationChain(llm=llm, memory=window_memory, verbose=False),\n",
    "        \"Summary\": ConversationChain(llm=llm, memory=summary_memory, verbose=False)\n",
    "    }\n",
    "    \n",
    "    # Secuencia de inputs para probar\n",
    "    test_inputs = [\n",
    "        \"Mi nombre es Alex y estudio ingenier√≠a inform√°tica\",\n",
    "        \"Tengo 22 a√±os y me especializo en IA\",\n",
    "        \"Mi lenguaje favorito es Python\",\n",
    "        \"Tambi√©n me gusta JavaScript para desarrollo web\",\n",
    "        \"¬øCu√°l es mi edad y carrera?\"  # Pregunta que requiere memoria\n",
    "    ]\n",
    "    \n",
    "    # Ejecutar la misma conversaci√≥n con cada tipo de memoria\n",
    "    for memory_type, conversation in conversations.items():\n",
    "        print(f\"\\\\n{'='*20} {memory_type.upper()} {'='*20}\")\n",
    "        \n",
    "        for i, user_input in enumerate(test_inputs, 1):\n",
    "            try:\n",
    "                if i < len(test_inputs):  # No mostrar la pregunta final a√∫n\n",
    "                    response = conversation.predict(input=user_input)\n",
    "                    print(f\"{i}. Input: {user_input}\")\n",
    "                    print(f\"   Respuesta: {response[:100]}...\")\n",
    "                else:  # Pregunta final para probar memoria\n",
    "                    response = conversation.predict(input=user_input)\n",
    "                    print(f\"\\\\n{i}. PREGUNTA DE MEMORIA: {user_input}\")\n",
    "                    print(f\"   RESPUESTA: {response}\")\n",
    "                    \n",
    "                    # Mostrar estado de memoria\n",
    "                    if memory_type == \"Buffer (Todo)\":\n",
    "                        print(f\"   Memoria: {len(buffer_memory.buffer)} caracteres\")\n",
    "                    elif memory_type == \"Window (k=2)\":\n",
    "                        print(f\"   Memoria: {len(window_memory.buffer)} caracteres\")\n",
    "                    else:\n",
    "                        print(f\"   Resumen: {len(summary_memory.buffer)} caracteres\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"   Error: {e}\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"-\"*60)\n",
    "    \n",
    "    print(\"\\\\n=== AN√ÅLISIS ===\")\n",
    "    print(\"‚Ä¢ Buffer Memory: Recuerda todo pero consume m√°s tokens\")\n",
    "    print(\"‚Ä¢ Window Memory: Eficiente pero puede olvidar informaci√≥n importante\")  \n",
    "    print(\"‚Ä¢ Summary Memory: Balance entre memoria y eficiencia\")\n",
    "\n",
    "# Ejecutar comparaci√≥n\n",
    "comparar_memorias()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a818257c",
   "metadata": {},
   "source": [
    "## Chatbot Avanzado con Memoria Personalizable\n",
    "\n",
    "Implementemos un chatbot que permite al usuario elegir el tipo de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96813f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot avanzado con memoria configurable\n",
    "def chatbot_con_memoria():\n",
    "    print(\"=== CHATBOT CON MEMORIA CONFIGURABLE ===\")\n",
    "    print(\"Tipos disponibles:\")\n",
    "    print(\"1. buffer - Mantiene todo el historial\")\n",
    "    print(\"2. window - Mantiene solo N mensajes recientes\") \n",
    "    print(\"3. summary - Resume conversaciones largas\")\n",
    "    print(\"\\\\nEscribe 'cambiar' para cambiar tipo de memoria\")\n",
    "    print(\"Escribe 'memoria' para ver el contenido actual\")\n",
    "    print(\"Escribe 'salir' para terminar\\\\n\")\n",
    "    \n",
    "    # Configuraci√≥n inicial\n",
    "    memory_type = \"buffer\"\n",
    "    memory = ConversationBufferMemory()\n",
    "    conversation = ConversationChain(llm=llm, memory=memory, verbose=False)\n",
    "    \n",
    "    def crear_memoria(tipo):\n",
    "        if tipo == \"buffer\":\n",
    "            return ConversationBufferMemory()\n",
    "        elif tipo == \"window\":\n",
    "            return ConversationBufferWindowMemory(k=3)\n",
    "        elif tipo == \"summary\":\n",
    "            return ConversationSummaryMemory(llm=llm)\n",
    "        else:\n",
    "            return ConversationBufferMemory()\n",
    "    \n",
    "    print(f\"Memoria actual: {memory_type}\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\\\nüßë T√∫: \")\n",
    "        \n",
    "        if user_input.lower() == 'salir':\n",
    "            print(\"\\\\nüëã ¬°Hasta luego!\")\n",
    "            break\n",
    "            \n",
    "        elif user_input.lower() == 'cambiar':\n",
    "            print(\"\\\\nTipos disponibles: buffer, window, summary\")\n",
    "            nuevo_tipo = input(\"Nuevo tipo de memoria: \").lower()\n",
    "            \n",
    "            if nuevo_tipo in ['buffer', 'window', 'summary']:\n",
    "                memory_type = nuevo_tipo\n",
    "                memory = crear_memoria(memory_type)\n",
    "                conversation = ConversationChain(llm=llm, memory=memory, verbose=False)\n",
    "                print(f\"‚úì Memoria cambiada a: {memory_type}\")\n",
    "                print(\"‚ö†Ô∏è Historial de conversaci√≥n reiniciado\")\n",
    "            else:\n",
    "                print(\"‚ùå Tipo no v√°lido\")\n",
    "            continue\n",
    "            \n",
    "        elif user_input.lower() == 'memoria':\n",
    "            print(f\"\\\\n=== MEMORIA ACTUAL ({memory_type}) ===\")\n",
    "            print(f\"Contenido: {memory.buffer}\")\n",
    "            print(f\"Longitud: {len(memory.buffer)} caracteres\")\n",
    "            continue\n",
    "            \n",
    "        elif not user_input.strip():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\\\nü§ñ Asistente ({memory_type}): \", end=\"\", flush=True)\n",
    "            response = conversation.predict(input=user_input)\n",
    "            print(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Funci√≥n para ejecutar el chatbot\n",
    "# chatbot_con_memoria()  # Descomenta para ejecutar\n",
    "\n",
    "print(\"üí° Descomenta la l√≠nea anterior para probar el chatbot con memoria configurable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85cfea",
   "metadata": {},
   "source": [
    "## Consideraciones T√©cnicas y Mejores Pr√°cticas\n",
    "\n",
    "### Selecci√≥n del Tipo de Memoria\n",
    "\n",
    "| Tipo | Cu√°ndo Usarlo | Ventajas | Desventajas |\n",
    "|------|---------------|----------|-------------|\n",
    "| **Buffer** | Conversaciones cortas | Contexto completo | Alto consumo de tokens |\n",
    "| **Window** | Contexto reciente importante | Eficiente en tokens | Puede perder informaci√≥n clave |\n",
    "| **Summary** | Conversaciones muy largas | Balance eficiencia/contexto | P√©rdida de detalles espec√≠ficos |\n",
    "\n",
    "### Mejores Pr√°cticas:\n",
    "\n",
    "1. **Gesti√≥n de Tokens**:\n",
    "   - Monitorea el uso de tokens regularmente\n",
    "   - Establece l√≠mites m√°ximos para evitar costos excesivos\n",
    "   - Considera el costo vs. calidad del contexto\n",
    "\n",
    "2. **Selecci√≥n Estrat√©gica**:\n",
    "   - Usa Buffer para sesiones cortas e importantes\n",
    "   - Usa Window para conversaciones con contexto limitado\n",
    "   - Usa Summary para sesiones largas de asistencia\n",
    "\n",
    "3. **Optimizaci√≥n**:\n",
    "   - Limpia memoria peri√≥dicamente si es necesario\n",
    "   - Implementa estrategias h√≠bridas seg√∫n el caso de uso\n",
    "   - Considera almacenamiento persistente para memoria a largo plazo\n",
    "\n",
    "## Ejercicios Pr√°cticos\n",
    "\n",
    "### Ejercicio 1: An√°lisis de Consumo\n",
    "Implementa un sistema que monitoree y reporte el uso de tokens con diferentes tipos de memoria.\n",
    "\n",
    "### Ejercicio 2: Memoria H√≠brida\n",
    "Dise√±a una estrategia que combine multiple tipos de memoria seg√∫n el contexto.\n",
    "\n",
    "### Ejercicio 3: Persistencia\n",
    "Extiende el chatbot para guardar y cargar memoria entre sesiones.\n",
    "\n",
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Importancia de la memoria** en conversaciones naturales\n",
    "2. **Tipos de memoria** y sus casos de uso espec√≠ficos\n",
    "3. **Balance** entre contexto y eficiencia de tokens\n",
    "4. **Implementaci√≥n pr√°ctica** con LangChain\n",
    "5. **Estrategias de optimizaci√≥n** para diferentes escenarios\n",
    "\n",
    "## Conclusi√≥n del M√≥dulo IL1.1\n",
    "\n",
    "Has completado la introducci√≥n a LLMs y conexiones API. Los conceptos aprendidos:\n",
    "\n",
    "1. **APIs directas** vs **frameworks** como LangChain\n",
    "2. **Streaming** para mejor experiencia de usuario\n",
    "3. **Memoria** para conversaciones contextuales\n",
    "4. **Mejores pr√°cticas** de seguridad y optimizaci√≥n\n",
    "\n",
    "### Pr√≥ximos Pasos\n",
    "En **IL1.2** exploraremos t√©cnicas avanzadas de **prompt engineering** incluyendo zero-shot, few-shot, y chain-of-thought prompting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
