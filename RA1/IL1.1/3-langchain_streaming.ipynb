{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hfn0f7nyumn",
   "metadata": {},
   "source": [
    "# 3. LangChain Streaming - Respuestas en Tiempo Real\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender qu√© es el streaming y cu√°ndo usarlo\n",
    "- Implementar streaming con LangChain\n",
    "- Manejar chunks de datos en tiempo real\n",
    "- Construir interfaces de usuario reactivas\n",
    "\n",
    "## ¬øQu√© es el Streaming?\n",
    "\n",
    "El streaming permite recibir la respuesta del modelo **token por token** conforme se genera, en lugar de esperar a que termine completamente. Esto mejora significativamente la experiencia de usuario en aplicaciones interactivas.\n",
    "\n",
    "### Ventajas del Streaming:\n",
    "- **Percepci√≥n de velocidad**: El usuario ve progreso inmediato\n",
    "- **Mejor UX**: Interfaces m√°s reactivas e interactivas  \n",
    "- **Engagement**: Mantiene la atenci√≥n del usuario\n",
    "- **Debugging**: Permite ver el proceso de generaci√≥n\n",
    "\n",
    "### Casos de Uso Ideales:\n",
    "- Chatbots y asistentes conversacionales\n",
    "- Generaci√≥n de contenido largo\n",
    "- Aplicaciones web interactivas\n",
    "- Demostraciones en vivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa694f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas correctamente para streaming\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Bibliotecas importadas correctamente para streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f037cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Modelo configurado con streaming habilitado\n",
      "Modelo: gpt-4o\n",
      "Streaming: True\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del modelo con streaming habilitado\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "        model=\"gpt-4o\",\n",
    "        streaming=True,  # ¬°Importante: habilitar streaming!\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(\"‚úì Modelo configurado con streaming habilitado\")\n",
    "    print(f\"Modelo: {llm.model_name}\")\n",
    "    print(f\"Streaming: {llm.streaming}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error en configuraci√≥n: {e}\")\n",
    "    print(\"Verifica las variables de entorno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da0d27",
   "metadata": {},
   "source": [
    "## Streaming B√°sico\n",
    "\n",
    "El m√©todo `.stream()` devuelve un generador que produce chunks de texto conforme se generan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f31f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING EN TIEMPO REAL ===\n",
      "Generando respuesta...\n",
      "--------------------------------------------------\n",
      "Hab√≠a una vez un programador llamado Mart√≠n, un hombre reservado y met√≥dico que dedicaba la mayor parte de su tiempo a escribir l√≠neas de c√≥digo en la soledad de su peque√±o apartamento. Su vida transcurr√≠a en una rutina predecible: trabajar, beber caf√©, solucionar errores, dormir, y repetir. Mart√≠n era un experto en su oficio, pero siempre hab√≠a sentido que algo faltaba en su vida, aunque no sab√≠a exactamente qu√©.\n",
      "\n",
      "Una noche, mientras trabajaba en un proyecto personal, Mart√≠n se encontr√≥ con un archivo misterioso en su computadora. El archivo no ten√≠a nombre y parec√≠a haber aparecido de la nada. A pesar de que era meticuloso con la seguridad de su sistema, no pudo resistirse a abrirlo.\n",
      "\n",
      "Dentro del archivo encontr√≥ un fragmento de c√≥digo que no se parec√≠a a nada que hubiese visto antes. Las l√≠neas parec√≠an brillar tenuemente, como si estuvieran vivas, y las palabras estaban escritas en un lenguaje que mezclaba s√≠mbolos matem√°ticos, palabras en idiomas desconocidos y lo que parec√≠a ser poes√≠a.\n",
      "\n",
      "Intrigado, Mart√≠n comenz√≥ a estudiar el c√≥digo. A medida que lo analizaba, se dio cuenta de que no se trataba solo de programaci√≥n convencional. Era algo m√°s. Cada l√≠nea parec√≠a contener una intenci√≥n, una emoci√≥n, una chispa de algo indescriptible. Sin darse cuenta, Mart√≠n empez√≥ a reescribir partes del c√≥digo, guiado por una intuici√≥n que nunca antes hab√≠a experimentado.\n",
      "\n",
      "Cuando ejecut√≥ el programa por primera vez, la pantalla de su computadora se apag√≥ de repente, y un destello de luz inund√≥ la habitaci√≥n. Al abrir los ojos, Mart√≠n se encontr√≥ de pie en un bosque brillante y surrealista, lleno de colores imposibles y criaturas que parec√≠an estar hechas de energ√≠a pura. Se dio cuenta de que el c√≥digo no era solo un programa: era un portal a otro mundo, un mundo donde la l√≥gica y la magia se entrelazaban.\n",
      "\n",
      "En este nuevo mundo, Mart√≠n descubri√≥ que el c√≥digo que escrib√≠a ten√≠a el poder de alterar la realidad. Pod√≠a crear puentes con solo teclear una funci√≥n, invocar lluvias de estrellas ajustando un bucle, o incluso comunicarse con las criaturas del bosque a trav√©s de variables y algoritmos. Lo que antes era solo una herramienta t√©cnica se hab√≠a convertido en un lenguaje universal, capaz de dar forma a la esencia misma de ese lugar.\n",
      "\n",
      "Pasaron d√≠as ‚Äîo quiz√°s semanas, ya que el tiempo parec√≠a comportarse de manera extra√±a en ese mundo‚Äî, y Mart√≠n se dio cuenta de que no quer√≠a regresar. Por primera vez en su vida, sent√≠a que su trabajo ten√≠a un prop√≥sito m√°s profundo, una conexi√≥n con algo m√°s grande que √©l mismo.\n",
      "\n",
      "Sin embargo, un d√≠a, una de las criaturas del bosque, una figura et√©rea que parec√≠a un c√∫mulo de estrellas, le habl√≥.\n",
      "\n",
      "‚ÄîMart√≠n, este mundo necesita equilibrio. No puedes quedarte para siempre, pero puedes llevar contigo lo que has aprendido.\n",
      "\n",
      "Mart√≠n despert√≥ en su apartamento, frente a su monitor, con el archivo misterioso a√∫n abierto. Pero algo hab√≠a cambiado. Ahora, cada vez que escrib√≠a c√≥digo, sent√≠a una chispa de esa magia. Su trabajo dej√≥ de ser solo l√≠neas de texto; se convirti√≥ en arte, en una forma de conectar con los dem√°s y con el universo.\n",
      "\n",
      "Desde ese d√≠a, Mart√≠n no volvi√≥ a ser el mismo. Su c√≥digo inspir√≥ a otros, resolvi√≥ problemas que parec√≠an imposibles y dej√≥ una huella en el mundo. Y aunque nunca volvi√≥ a encontrar el portal, sab√≠a que la magia segu√≠a ah√≠, escondida entre las l√≠neas de cada programa que escrib√≠a. \n",
      "--------------------------------------------------\n",
      "‚úì Streaming completado\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo b√°sico de streaming\n",
    "def streaming_basico():\n",
    "    prompt = \"Cu√©ntame una historia corta sobre un programador que descubre la magia en el c√≥digo\"\n",
    "    \n",
    "    print(\"=== STREAMING EN TIEMPO REAL ===\")\n",
    "    print(\"Generando respuesta...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # stream() devuelve un generador de chunks\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Imprimir cada chunk sin nueva l√≠nea\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.01)  # Peque√±a pausa para simular streaming visual\n",
    "            \n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"‚úì Streaming completado\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error en streaming: {e}\")\n",
    "\n",
    "# Ejecutar streaming b√°sico\n",
    "streaming_basico()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6214408",
   "metadata": {},
   "source": [
    "## Comparaci√≥n: Streaming vs No-Streaming\n",
    "\n",
    "Veamos la diferencia en experiencia de usuario entre ambos enfoques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8e5874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACI√ìN: STREAMING vs NO-STREAMING ===\\n\n",
      "1. SIN STREAMING:\n",
      "--------------------\n",
      "Esperando respuesta completa...\n",
      "\\n[Respuesta recibida despu√©s de 3.20 segundos]\n",
      "Python es un lenguaje de programaci√≥n altamente vers√°til y popular debido a sus numerosas ventajas. Su sintaxis simple y legible facilita el aprendizaje para principiantes y acelera el desarrollo para programadores experimentados, permitiendo centrarse en la l√≥gica del problema en lugar de detalles t√©cnicos complejos. Adem√°s, Python cuenta con una amplia biblioteca est√°ndar y un ecosistema de paquetes de terceros que simplifican tareas como an√°lisis de datos, desarrollo web, inteligencia artificial, automatizaci√≥n y m√°s. Su naturaleza multiplataforma lo hace compatible con diversos sistemas operativos, y su comunidad activa proporciona soporte constante, recursos educativos y actualizaciones regulares. Estas caracter√≠sticas convierten a Python en una herramienta poderosa tanto para proyectos peque√±os como para aplicaciones de gran escala en m√∫ltiples industrias.\n",
      "\\n============================================================\\n\n",
      "2. CON STREAMING:\n",
      "------------------\n",
      "Respuesta en tiempo real:\n",
      "Python es un lenguaje de programaci√≥n sumamente vers√°til y accesible, lo que lo convierte en una excelente opci√≥n tanto para principiantes como para desarrolladores experimentados. Una de sus principales ventajas es su sintaxis clara y sencilla, que facilita la escritura y lectura del c√≥digo, reduciendo el tiempo de desarrollo y minimizando errores. Adem√°s, cuenta con una vasta comunidad global que aporta soporte, documentaci√≥n y una gran cantidad de bibliotecas y frameworks, como NumPy, pandas, Django o TensorFlow, que permiten abordar proyectos en √°reas como an√°lisis de datos, desarrollo web, inteligencia artificial y m√°s. Python es tambi√©n multiplataforma, lo que significa que los programas pueden ejecutarse en diferentes sistemas operativos sin grandes modificaciones. Su flexibilidad, combinado con su enfoque en la productividad y su capacidad para integrarse con otros lenguajes, lo convierten en una herramienta poderosa para resolver problemas complejos en diversos campos.\\n\\n[Streaming completado en 7.28 segundos]\n",
      "\\n============================================================\n",
      "OBSERVACIONES:\n",
      "- Sin streaming: El usuario espera sin feedback\n",
      "- Con streaming: El usuario ve progreso inmediato\n",
      "- Mejor percepci√≥n de velocidad con streaming\n",
      "- Streaming es especial para respuestas largas\n"
     ]
    }
   ],
   "source": [
    "# Comparaci√≥n entre streaming y no-streaming\n",
    "def comparar_streaming():\n",
    "    # Modelo sin streaming\n",
    "    llm_no_stream = ChatOpenAI(\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "        model=\"gpt-4o\",\n",
    "        streaming=False,  # Sin streaming\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    prompt = \"Escribe un p√°rrafo sobre las ventajas de la programaci√≥n en Python\"\n",
    "    \n",
    "    print(\"=== COMPARACI√ìN: STREAMING vs NO-STREAMING ===\\\\n\")\n",
    "    \n",
    "    # 1. Sin streaming\n",
    "    print(\"1. SIN STREAMING:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Esperando respuesta completa...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = llm_no_stream.invoke([HumanMessage(content=prompt)])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\\\n[Respuesta recibida despu√©s de {end_time - start_time:.2f} segundos]\")\n",
    "        print(response.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60 + \"\\\\n\")\n",
    "    \n",
    "    # 2. Con streaming\n",
    "    print(\"2. CON STREAMING:\")\n",
    "    print(\"-\" * 18)\n",
    "    print(\"Respuesta en tiempo real:\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.03)  # Simular pausa para efecto visual\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"\\\\n\\\\n[Streaming completado en {end_time - start_time:.2f} segundos]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"OBSERVACIONES:\")\n",
    "    print(\"- Sin streaming: El usuario espera sin feedback\")\n",
    "    print(\"- Con streaming: El usuario ve progreso inmediato\")\n",
    "    print(\"- Mejor percepci√≥n de velocidad con streaming\")\n",
    "    print(\"- Streaming es especial para respuestas largas\")\n",
    "\n",
    "# Ejecutar comparaci√≥n\n",
    "comparar_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ad79d",
   "metadata": {},
   "source": [
    "## Implementaci√≥n de un Chatbot Simple con Streaming\n",
    "\n",
    "Creemos un chatbot b√°sico que demuestre el streaming en un contexto pr√°ctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a03cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHATBOT CON STREAMING ===\n",
      "Escribe 'salir' para terminar la conversaci√≥n\\n\n",
      "\\nü§ñ Asistente: ¬°Hola! üòä ¬øEn qu√© puedo ayudarte hoy?\n",
      "\\nü§ñ Asistente: ¬°Claro! Aqu√≠ tienes un poema breve:  \n",
      "\n",
      "En el susurro del viento callado,  \n",
      "las estrellas dibujan sue√±os dorados,  \n",
      "y la noche abraza el alma cansada.  \n",
      "\n",
      "¬øQu√© te parece? üòä\n",
      "\\nü§ñ Asistente: ¬°De nada! üòä Si necesitas ayuda con algo, no dudes en preguntar. Estoy aqu√≠ para ayudarte. üöÄ\n",
      "\\nüëã ¬°Hasta luego!\n",
      "\\n¬°Gracias por usar el chatbot!\n",
      "üí° Descomenta la l√≠nea anterior para probar el chatbot interactivo\n"
     ]
    }
   ],
   "source": [
    "# Chatbot simple con streaming\n",
    "def chatbot_streaming():\n",
    "    print(\"=== CHATBOT CON STREAMING ===\")\n",
    "    print(\"Escribe 'salir' para terminar la conversaci√≥n\\\\n\")\n",
    "    \n",
    "    # Configurar asistente con personalidad\n",
    "    system_message = \"\"\"Eres un asistente √∫til y amigable especializado en tecnolog√≠a. \n",
    "    Respondes de manera clara y concisa, y siempre intentas ser educativo.\"\"\"\n",
    "    \n",
    "    while True:\n",
    "        # Obtener input del usuario\n",
    "        user_input = input(\"\\\\nüßë T√∫: \")\n",
    "        \n",
    "        if user_input.lower() in ['salir', 'exit', 'quit']:\n",
    "            print(\"\\\\nüëã ¬°Hasta luego!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input.strip():\n",
    "            continue\n",
    "            \n",
    "        print(\"\\\\nü§ñ Asistente: \", end=\"\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            # Streaming de la respuesta\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "            \n",
    "            # Convertir a formato LangChain\n",
    "            from langchain.schema import SystemMessage\n",
    "            lc_messages = [\n",
    "                SystemMessage(content=system_message),\n",
    "                HumanMessage(content=user_input)\n",
    "            ]\n",
    "            \n",
    "            full_response = \"\"\n",
    "            for chunk in llm.stream(lc_messages):\n",
    "                content = chunk.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "                time.sleep(0.02)\n",
    "                \n",
    "            print()  # Nueva l√≠nea al final\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\\\n\\\\n‚è∏Ô∏è Interrumpido por el usuario\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\\\n‚ùå Error: {e}\")\n",
    "            \n",
    "    print(\"\\\\n¬°Gracias por usar el chatbot!\")\n",
    "\n",
    "# Ejecutar chatbot (¬°Pru√©balo!)\n",
    "# chatbot_streaming()  # Descomenta esta l√≠nea para ejecutar\n",
    "\n",
    "print(\"üí° Descomenta la l√≠nea anterior para probar el chatbot interactivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060e43c",
   "metadata": {},
   "source": [
    "## Streaming Avanzado con Manejo de Chunks\n",
    "\n",
    "Podemos procesar cada chunk individualmente para crear experiencias m√°s sofisticadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86fa1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING AVANZADO CON AN√ÅLISIS ===\n",
      "Analizando chunks conforme llegan...\n",
      "\n",
      "¬°Por supuesto! Vamos a des\\n[Progreso: 10 chunks, ~8 palabras]\\n\n",
      "glosar estos conceptos de manera sencilla:\n",
      "\n",
      "###\\n[Progreso: 20 chunks, ~18 palabras]\\n\n",
      " **¬øQu√© es la Inteligencia Artificial (IA\\n[Progreso: 30 chunks, ~28 palabras]\\n\n",
      ")?**\n",
      "La **Inteligencia Artificial (IA\\n[Progreso: 40 chunks, ~38 palabras]\\n\n",
      ")** es un campo de la inform√°tica que se centra\\n[Progreso: 50 chunks, ~48 palabras]\\n\n",
      " en la creaci√≥n de sistemas capaces de realizar tareas que\\n[Progreso: 60 chunks, ~58 palabras]\\n\n",
      " normalmente requieren inteligencia humana. Estas tareas pueden incluir el\\n[Progreso: 70 chunks, ~68 palabras]\\n\n",
      " reconocimiento de voz, la toma de decisiones, la\\n[Progreso: 80 chunks, ~78 palabras]\\n\n",
      " resoluci√≥n de problemas, el aprendizaje, la planificaci√≥n y\\n[Progreso: 90 chunks, ~88 palabras]\\n\n",
      " la comprensi√≥n del lenguaje natural.\n",
      "\n",
      "En otras palabras,\\n[Progreso: 100 chunks, ~98 palabras]\\n\n",
      " la IA busca que las m√°quinas \"piensen\"\\n[Progreso: 110 chunks, ~108 palabras]\\n\n",
      " o act√∫en como humanos, aunque no necesariamente\\n[Progreso: 120 chunks, ~118 palabras]\\n\n",
      " de la misma manera que nuestro cerebro. Los sistemas\\n[Progreso: 130 chunks, ~128 palabras]\\n\n",
      " de IA pueden ser dise√±ados para tareas espec√≠ficas (\\n[Progreso: 140 chunks, ~138 palabras]\\n\n",
      "IA estrecha o d√©bil), como los asistentes\\n[Progreso: 150 chunks, ~148 palabras]\\n\n",
      " virtuales (por ejemplo, Siri o Alexa),\\n[Progreso: 160 chunks, ~158 palabras]\\n\n",
      " o para tareas m√°s amplias y complejas (\\n[Progreso: 170 chunks, ~168 palabras]\\n\n",
      "IA general o fuerte), aunque esta √∫ltima a√∫n est√°\\n[Progreso: 180 chunks, ~178 palabras]\\n\n",
      " en desarrollo.\n",
      "\n",
      "---\n",
      "\n",
      "### **¬øQu√© es el\\n[Progreso: 190 chunks, ~188 palabras]\\n\n",
      " Machine Learning (ML) y c√≥mo funciona?**\n",
      "\\n[Progreso: 200 chunks, ~198 palabras]\\n\n",
      "El **Machine Learning (Aprendizaje Autom√°tico\\n[Progreso: 210 chunks, ~208 palabras]\\n\n",
      ")** es una rama de la IA que permite a\\n[Progreso: 220 chunks, ~218 palabras]\\n\n",
      " las m√°quinas aprender de los datos y mejorar su rendimiento\\n[Progreso: 230 chunks, ~228 palabras]\\n\n",
      " en tareas espec√≠ficas sin necesidad de ser programadas expl√≠c\\n[Progreso: 240 chunks, ~238 palabras]\\n\n",
      "itamente para cada caso. En lugar de decirle\\n[Progreso: 250 chunks, ~248 palabras]\\n\n",
      " a una m√°quina exactamente qu√© hacer, se le proporciona\\n[Progreso: 260 chunks, ~258 palabras]\\n\n",
      " un conjunto de datos para que \"aprenda\"\\n[Progreso: 270 chunks, ~268 palabras]\\n\n",
      " y descubra patrones por s√≠ misma.\n",
      "\n",
      "#### **\\n[Progreso: 280 chunks, ~278 palabras]\\n\n",
      "¬øC√≥mo funciona el Machine Learning?**\n",
      "El proceso\\n[Progreso: 290 chunks, ~288 palabras]\\n\n",
      " de ML usualmente sigue estos pasos principales:\n",
      "\n",
      "1\\n[Progreso: 300 chunks, ~298 palabras]\\n\n",
      ". **Recolecci√≥n de Datos:** \n",
      "  \\n[Progreso: 310 chunks, ~306 palabras]\\n\n",
      " Se recopilan datos relevantes (por ejemplo, im√°genes\\n[Progreso: 320 chunks, ~316 palabras]\\n\n",
      ", texto, n√∫meros, etc.) que servir√°n\\n[Progreso: 330 chunks, ~326 palabras]\\n\n",
      " como base para el aprendizaje.\n",
      "\n",
      "2. **Prepar\\n[Progreso: 340 chunks, ~336 palabras]\\n\n",
      "aci√≥n y Limpieza:** \n",
      "   Los datos se\\n[Progreso: 350 chunks, ~344 palabras]\\n\n",
      " organizan y se limpian para eliminar valores incorrect\\n[Progreso: 360 chunks, ~354 palabras]\\n\n",
      "os, duplicados o inconsistencias. Esto asegura\\n[Progreso: 370 chunks, ~364 palabras]\\n\n",
      " que el modelo pueda aprender correctamente.\n",
      "\n",
      "3. **\\n[Progreso: 380 chunks, ~374 palabras]\\n\n",
      "Elecci√≥n del Algoritmo:** \n",
      "   Se\\n[Progreso: 390 chunks, ~382 palabras]\\n\n",
      " selecciona un algoritmo de aprendizaje. Algunos ejemplos comunes\\n[Progreso: 400 chunks, ~392 palabras]\\n\n",
      " son:\n",
      "   - **Regresi√≥n Lineal:**\\n[Progreso: 410 chunks, ~401 palabras]\\n\n",
      " Para predecir valores continuos (como los\\n[Progreso: 420 chunks, ~411 palabras]\\n\n",
      " precios de casas).\n",
      "   - **√Årbol\\n[Progreso: 430 chunks, ~420 palabras]\\n\n",
      "es de Decisi√≥n:** Para clasificar o tomar\\n[Progreso: 440 chunks, ~430 palabras]\\n\n",
      " decisiones.\n",
      "   - **Redes Neuronales\\n[Progreso: 450 chunks, ~439 palabras]\\n\n",
      ":** Inspiradas en el cerebro humano, √∫tiles para\\n[Progreso: 460 chunks, ~449 palabras]\\n\n",
      " tareas complejas como reconocimiento de im√°genes.\n",
      "\n",
      "4.\\n[Progreso: 470 chunks, ~459 palabras]\\n\n",
      " **Entrenamiento del Modelo:** \n",
      "   El\\n[Progreso: 480 chunks, ~467 palabras]\\n\n",
      " modelo de ML procesa los datos de entrenamiento (un\\n[Progreso: 490 chunks, ~477 palabras]\\n\n",
      " subconjunto de los datos originales) y ajusta\\n[Progreso: 500 chunks, ~487 palabras]\\n\n",
      " sus par√°metros internos para aprender patrones en los datos.\n",
      "\n",
      "\\n[Progreso: 510 chunks, ~497 palabras]\\n\n",
      "5. **Evaluaci√≥n:** \n",
      "   Despu√©s del\\n[Progreso: 520 chunks, ~505 palabras]\\n\n",
      " entrenamiento, el modelo se prueba con datos nuevos (\\n[Progreso: 530 chunks, ~515 palabras]\\n\n",
      "datos de prueba) para medir su precisi√≥n y desempe√±o\\n[Progreso: 540 chunks, ~525 palabras]\\n\n",
      ".\n",
      "\n",
      "6. **Predicciones:** \n",
      "   Una\\n[Progreso: 550 chunks, ~533 palabras]\\n\n",
      " vez entrenado y evaluado, el modelo puede\\n[Progreso: 560 chunks, ~543 palabras]\\n\n",
      " hacer predicciones o tomar decisiones en base a nuevos\\n[Progreso: 570 chunks, ~553 palabras]\\n\n",
      " datos.\n",
      "\n",
      "---\n",
      "\n",
      "### **Tipos de Machine Learning**\n",
      "\\n[Progreso: 580 chunks, ~563 palabras]\\n\n",
      "Existen tres tipos principales de aprendizaje en ML:\n",
      "\n",
      "\\n[Progreso: 590 chunks, ~573 palabras]\\n\n",
      "1. **Aprendizaje Supervisado:** \n",
      "\\n[Progreso: 600 chunks, ~581 palabras]\\n\n",
      "   El modelo aprende a partir de datos etiquet\\n[Progreso: 610 chunks, ~591 palabras]\\n\n",
      "ados. Por ejemplo, si quieres que un modelo\\n[Progreso: 620 chunks, ~601 palabras]\\n\n",
      " detecte correos spam, le proporcionar√≠as ejemplos\\n[Progreso: 630 chunks, ~611 palabras]\\n\n",
      " de correos etiquetados como \"spam\"\\n[Progreso: 640 chunks, ~621 palabras]\\n\n",
      " o \"no spam\".\n",
      "\n",
      "2. **Aprendiz\\n[Progreso: 650 chunks, ~631 palabras]\\n\n",
      "aje No Supervisado:** \n",
      "   El modelo trabaja\\n[Progreso: 660 chunks, ~639 palabras]\\n\n",
      " con datos no etiquetados y busca patrones o\\n[Progreso: 670 chunks, ~649 palabras]\\n\n",
      " agrupaciones por s√≠ mismo. Por ejemplo, agr\\n[Progreso: 680 chunks, ~659 palabras]\\n\n",
      "upar clientes en segmentos seg√∫n su comportamiento de compra.\n",
      "\n",
      "\\n[Progreso: 690 chunks, ~669 palabras]\\n\n",
      "3. **Aprendizaje por Refuerzo:**\\n[Progreso: 700 chunks, ~678 palabras]\\n\n",
      " \n",
      "   Aqu√≠, el modelo aprende a trav√©s de\\n[Progreso: 710 chunks, ~687 palabras]\\n\n",
      " ensayo y error, recibiendo recompensas o\\n[Progreso: 720 chunks, ~697 palabras]\\n\n",
      " penalizaciones seg√∫n sus acciones, como en el caso\\n[Progreso: 730 chunks, ~707 palabras]\\n\n",
      " de entrenar a una IA para jugar videojuegos.\n",
      "\n",
      "\\n[Progreso: 740 chunks, ~717 palabras]\\n\n",
      "---\n",
      "\n",
      "### **Conexi√≥n entre IA y Machine\\n[Progreso: 750 chunks, ~727 palabras]\\n\n",
      " Learning**\n",
      "El Machine Learning es una **subcategor\\n[Progreso: 760 chunks, ~737 palabras]\\n\n",
      "√≠a de la IA**. Mientras que la IA\\n[Progreso: 770 chunks, ~747 palabras]\\n\n",
      " es un concepto m√°s amplio que incluye cualquier m√°quina que\\n[Progreso: 780 chunks, ~757 palabras]\\n\n",
      " simule inteligencia, el Machine Learning es un enfoque\\n[Progreso: 790 chunks, ~767 palabras]\\n\n",
      " espec√≠fico para lograr esto mediante el aprendizaje a partir de\\n[Progreso: 800 chunks, ~777 palabras]\\n\n",
      " datos.\n",
      "\n",
      "Por ejemplo:\n",
      "- IA: Un coche\\n[Progreso: 810 chunks, ~787 palabras]\\n\n",
      " aut√≥nomo toma decisiones en tiempo real para conducir.\n",
      "\\n[Progreso: 820 chunks, ~797 palabras]\\n\n",
      "- ML: El coche aut√≥nomo utiliza ML para\\n[Progreso: 830 chunks, ~807 palabras]\\n\n",
      " reconocer se√±ales de tr√°fico o peatones bas√°ndose en\\n[Progreso: 840 chunks, ~817 palabras]\\n\n",
      " datos previos.\n",
      "\n",
      "---\n",
      "\n",
      "En resumen, la inteligencia\\n[Progreso: 850 chunks, ~827 palabras]\\n\n",
      " artificial busca que las m√°quinas sean \"inteligentes\\n[Progreso: 860 chunks, ~837 palabras]\\n\n",
      "\", y el machine learning es una de las herramientas\\n[Progreso: 870 chunks, ~847 palabras]\\n\n",
      " m√°s poderosas para lograrlo, ya que permite\\n[Progreso: 880 chunks, ~857 palabras]\\n\n",
      " a las m√°quinas aprender y adaptarse en lugar de\\n[Progreso: 890 chunks, ~867 palabras]\\n\n",
      " depender √∫nicamente de reglas predefinidas.\\n\\n=== ESTAD√çSTICAS FINALES ===\n",
      "Total de chunks: 899\n",
      "Palabras aproximadas: 875\n",
      "Caracteres totales: 4140\n",
      "Promedio chars/chunk: 4.6\n"
     ]
    }
   ],
   "source": [
    "# Streaming con an√°lisis de chunks\n",
    "def streaming_avanzado():\n",
    "    prompt = \"Explica qu√© es la inteligencia artificial y c√≥mo funciona el machine learning\"\n",
    "    \n",
    "    print(\"=== STREAMING AVANZADO CON AN√ÅLISIS ===\")\n",
    "    print(\"Analizando chunks conforme llegan...\\n\")\n",
    "    \n",
    "    # Variables para estad√≠sticas\n",
    "    chunk_count = 0\n",
    "    total_content = \"\"\n",
    "    words_processed = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            chunk_count += 1\n",
    "            content = chunk.content\n",
    "            total_content += content\n",
    "            \n",
    "            # Contar palabras aproximadas\n",
    "            if content.strip():\n",
    "                words_in_chunk = len(content.split())\n",
    "                words_processed += words_in_chunk\n",
    "            \n",
    "            # Mostrar progreso cada 10 chunks\n",
    "            if chunk_count % 10 == 0:\n",
    "                print(f\"\\\\n[Progreso: {chunk_count} chunks, ~{words_processed} palabras]\\\\n\")\n",
    "            \n",
    "            # Imprimir el contenido\n",
    "            print(content, end=\"\", flush=True)\n",
    "            time.sleep(0.02)  # Pausa ligeramente m√°s larga para ver el an√°lisis\n",
    "        \n",
    "        # Estad√≠sticas finales\n",
    "        print(f\"\\\\n\\\\n=== ESTAD√çSTICAS FINALES ===\")\n",
    "        print(f\"Total de chunks: {chunk_count}\")\n",
    "        print(f\"Palabras aproximadas: {words_processed}\")\n",
    "        print(f\"Caracteres totales: {len(total_content)}\")\n",
    "        print(f\"Promedio chars/chunk: {len(total_content)/chunk_count if chunk_count > 0 else 0:.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\n‚úó Error: {e}\")\n",
    "\n",
    "# Ejecutar streaming avanzado\n",
    "streaming_avanzado()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac251a9d",
   "metadata": {},
   "source": [
    "## Consideraciones T√©cnicas del Streaming\n",
    "\n",
    "### Cu√°ndo Usar Streaming:\n",
    "‚úÖ **S√ç usar streaming:**\n",
    "- Respuestas largas (>100 tokens)\n",
    "- Aplicaciones interactivas\n",
    "- Chatbots y asistentes\n",
    "- Demostraciones en vivo\n",
    "- Cuando la UX es prioritaria\n",
    "\n",
    "‚ùå **NO usar streaming:**\n",
    "- Respuestas muy cortas\n",
    "- Procesamiento batch\n",
    "- APIs de backend sin interfaz\n",
    "- Cuando necesitas la respuesta completa antes de procesar\n",
    "\n",
    "### Mejores Pr√°cticas:\n",
    "1. **Manejo de errores**: Siempre incluye try/catch\n",
    "2. **Indicadores visuales**: Muestra progreso al usuario\n",
    "3. **Cancelaci√≥n**: Permite al usuario interrumpir\n",
    "4. **Buffer management**: Para interfaces web, considera buffering\n",
    "5. **Performance**: Monitorea el uso de recursos\n",
    "\n",
    "## Ejercicios Pr√°cticos\n",
    "\n",
    "### Ejercicio 1: Indicador de Progreso\n",
    "Modifica el c√≥digo para mostrar un indicador de progreso (spinner, barra, porcentaje).\n",
    "\n",
    "### Ejercicio 2: Streaming con Filtros\n",
    "Implementa streaming que filtre o procese chunks espec√≠ficos (ej: resaltar palabras clave).\n",
    "\n",
    "### Ejercicio 3: Chatbot Mejorado\n",
    "Extiende el chatbot con:\n",
    "- Historial de conversaci√≥n\n",
    "- Comandos especiales (/help, /clear)\n",
    "- Diferentes personalidades\n",
    "\n",
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Streaming** mejora la percepci√≥n de velocidad\n",
    "2. **Chunks** se procesan individualmente en tiempo real\n",
    "3. **UX** es significativamente mejor con streaming\n",
    "4. **Implementaci√≥n** requiere manejo cuidadoso de generadores\n",
    "5. **Casos de uso** espec√≠ficos donde streaming aporta valor\n",
    "\n",
    "## Pr√≥ximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos la **memoria en LangChain**, que nos permite mantener contexto entre m√∫ltiples interacciones del usuario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
